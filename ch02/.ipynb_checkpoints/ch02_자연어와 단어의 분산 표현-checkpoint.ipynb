{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T18:14:16.147409Z",
     "start_time": "2019-12-27T18:14:16.143786Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시소러스\n",
    "\n",
    ": <u>사람의 손</u>으로 만든 thesaurus (유의어 사전)\n",
    "\n",
    "- 사람의 힘이 들어가기 때문에 노동의 비용이 크다\n",
    "- 시대의 변화에 대응하기 힘들다. \n",
    "- 단어의 미묘한 차이를 표현하기 힘들다. (e.g., vintage, retro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통계 기반 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T15:04:31.073348Z",
     "start_time": "2019-12-27T15:04:31.062857Z"
    }
   },
   "source": [
    "## 파이썬으로 말뭉치 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T15:08:13.779639Z",
     "start_time": "2019-12-27T15:08:13.770906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "\n",
    "text = text.lower()\n",
    "text = text.replace('.',' .')\n",
    "words = text.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T15:13:53.849912Z",
     "start_time": "2019-12-27T15:13:53.839040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "# 단어에 ID 부여하기\n",
    "\n",
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "#for i,word in enumerate(words): \n",
    "# enumerate 방식으로 id를 할당하면 중복단어 등장했을 때 index가 다 채워지지 않음! \n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word\n",
    "        \n",
    "print(word_to_id)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T15:13:26.484056Z",
     "start_time": "2019-12-27T15:13:26.478547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word[3])\n",
    "print(word_to_id['hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T15:15:37.334963Z",
     "start_time": "2019-12-27T15:15:37.319961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 목록을 단어 ID 목록으로 변경하기\n",
    "\n",
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T15:18:35.731974Z",
     "start_time": "2019-12-27T15:18:35.711077Z"
    }
   },
   "outputs": [],
   "source": [
    "# 함수화 \n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    # 간단한 전처리\n",
    "    text = text.lower()\n",
    "    text = text.replace('.',' .')\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    # 단어를 Id로\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    \n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어의 분산표현\n",
    "\n",
    "**단어의 의미** 를 정확하게 파악할 수 있는 벡터 표현. <u>단어를 벡터로.</u>\n",
    "\n",
    "이를 자연어 처리 분야에서는 **단어의 분산 표현 <sup>distributional representation</sup>** 이라고 말한다.\n",
    "\n",
    "## 분포 가설\n",
    "\n",
    ": ```단어의 의미는 주변 단어에 의해 형성된다``` \n",
    "\n",
    "단어 자체에는 의미가 없고, 그 단어가 사용된 맥락(Context)가 그 단어의 의미를 형성한다!\n",
    "\n",
    "```\n",
    "You say goodbye and i say hello.\n",
    "```\n",
    "\n",
    "맥락의 크기 (주변의 단어를 몇 개나 포함할 지) 를 윈도우 크기<sup>window size</sup>라고 한다.\n",
    "\n",
    "윈도우 크기가 1이면 좌우 한 단어, 2이면 좌우 두 단어가 맥락에 포함된다.\n",
    "\n",
    "위 예시에서 단어 'goodbye'에 주목할 때, window size = 2라면 you, say, and, i를 goodbye의 맥락에 이용함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T15:30:28.055527Z",
     "start_time": "2019-12-27T15:30:28.051703Z"
    }
   },
   "source": [
    "## 동시발생 행렬\n",
    "\n",
    "어떤 단어에 주목했을 때, **그 주변에 어떤 단어가 몇 번이나 등장하는지를 세어** 집계하는 방법\n",
    "\n",
    ":`통계 기반 기법`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T15:37:12.981757Z",
     "start_time": "2019-12-27T15:37:12.976925Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # sys.path.append('모듈을 저장한 디렉토리')\n",
    "from common_wj.util import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T16:41:27.248254Z",
     "start_time": "2019-12-27T16:41:27.242716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 `You`,`say`의 맥락을 세어보기 \n",
    "\n",
    "\n",
    "<center> window_size = 1인 동시 발생 행렬</center>\n",
    "    \n",
    "|     | you | say | goodbye | and | i | hello | . |\n",
    "|-----|:---:|:---:|:-------:|:---:|:-:|:-----:|:-:|\n",
    "| you |  0  |  1  |    0    |  0  | 0 |   0   | 0 |\n",
    "| say | 1   | 0   | 1       | 0   | 1 | 1     | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T17:11:18.697782Z",
     "start_time": "2019-12-27T17:11:18.687475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 동시 발생행렬 구현해보기\n",
    "def create_co_matrix(corpus,vocab_size,window_size=1):\n",
    "\n",
    "    # corpus : 단어 아이디의 리스트\n",
    "    # vocab_size : 어휘 수 \n",
    "    \n",
    "    corpus_size = len(corpus) # 단어의 숫자 \n",
    "    co_matrix = np.zeros((vocab_size,vocab_size),dtype = np.int32)\n",
    "\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size+1):\n",
    "            left_idx = idx - i # 윈도우 사이즈만큼 왼쪽으로\n",
    "            right_idx = idx + i # 윈도우 사이즈만큼 오른쪽으로\n",
    "            \n",
    "            if left_idx >= 0: # 문장 빠져나가지 않을 때까지\n",
    "                left_word_id = corpus[left_idx] # index를 통해 단어의 id로 구성된 corpus를 통해 id 받아냄\n",
    "                co_matrix[word_id][left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id][right_word_id] += 1\n",
    "\n",
    "    return co_matrix\n",
    "    \n",
    "co_matrix = create_co_matrix(corpus,len(word_to_id),window_size=1)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T16:37:44.158802Z",
     "start_time": "2019-12-27T16:37:44.152895Z"
    }
   },
   "source": [
    "## 벡터 간 유사도\n",
    "\n",
    "**코사인 유사도 cosine similarity**\n",
    "\n",
    "$$similarity (x,y) = \\frac{x\\cdot y}{\\lVert x\\rVert \\lVert y\\rVert} $$\n",
    "\n",
    "<br></br>\n",
    "<center>두 벡터가 완전히 같다면 1, 완전히 반대라면 -1</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T16:54:43.155548Z",
     "start_time": "2019-12-27T16:54:43.133618Z"
    }
   },
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    # epsilon을 추가하여 divide by zero 오류 방지\n",
    "    nx = x / np.sqrt(np.sum(x**2) + eps) # x의 정규화\n",
    "    ny = y / np.sqrt(np.sum(y**2) + eps) # y의 정규화\n",
    "    return np.dot(nx,ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T16:59:01.271035Z",
     "start_time": "2019-12-27T16:59:01.265044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067811865475\n"
     ]
    }
   ],
   "source": [
    "# \"you\"와 \"i\"의 유사도 구하기\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']] # you의 단어 벡터\n",
    "c1 = C[word_to_id['i']] # i의 단어 벡터 \n",
    "\n",
    "print(cos_similarity(c0,c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유사 단어의 랭킹 표시\n",
    "```python\n",
    "most_similar(query, word_to_id, id_to_word, word_matrix, top = 5)\n",
    "```\n",
    "\n",
    "- query : 검색어 (단어)\n",
    "- word_to_id : 단어에서 단어 ID로의 딕셔너리\n",
    "- id_to_word : 단어 ID에서 단어로의 딕셔너리\n",
    "- word_matrix : 단어 벡터들을 한데 모든 행렬. 각 행에는 대응하는 단어의 벡터가 저장되어 있다고 가정한다.\n",
    "- top : 상위 몇 개까지 출력할지 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T17:11:22.051017Z",
     "start_time": "2019-12-27T17:11:22.042721Z"
    }
   },
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top = 5):\n",
    "    \n",
    "    # 검색어 찾기\n",
    "    if query not in word_to_id:\n",
    "        print(\"%s 를 찾을 수 없습니다.\" % query)\n",
    "        return ;\n",
    "    \n",
    "    # 검색어의 단어 벡터 꺼낸다\n",
    "    print(\"\\n[query]\" + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # 코사인 유사도 계산\n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(query_vec, word_matrix[i])\n",
    "    \n",
    "    # 코사인 유사도를 기준으로 내림차순 출력\n",
    "    count = 0\n",
    "    # -1를 곱해주는 이유\n",
    "    # argsort()는 배열의 원소를 낮은 순서부터 정렬해주는 메서드\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query: # 자기 자신은 패스\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i],similarity[i]))\n",
    "        \n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T17:11:49.215811Z",
     "start_time": "2019-12-27T17:11:49.202487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query]you\n",
      " goodbye: 0.7071067811865475\n",
      " i: 0.7071067811865475\n",
      " hello: 0.7071067811865475\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "most_similar('you',word_to_id, id_to_word, co_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통계 기반 기법 개선하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상호정보량\n",
    "\n",
    "동시발생 행렬의 원소는 두 단어가 동시에 발생한 횟수를 나타낸다. \n",
    "\n",
    "그러나 고빈도 단어 (e.g, the,a )를 고려한다면 이는 좋은 방법이 아니다.\n",
    "\n",
    "`the`는 고빈도 단어이기 때문에 다른 단어와 높은 관련성을 가질 확률이 높다.\n",
    "\n",
    "---\n",
    "이 문제를 해결하기 위해 점별 상호정보량 <sup>Pointwise Mutual Information</sup> (PMI) 라는 척도를 사용한다.\n",
    "\n",
    "PMI는 확률 변수 x와 y에 대해 다음과 같이 정의된다.\n",
    "\n",
    "$$ PMI(x,y) = log_2\\frac{P(x,y)}{P(x)P(y)} $$\n",
    "<br></br>\n",
    "<center>P(x)는 x가 일어날 확률, P(y)는 y가 일어날 확률, P(x,y)는 x와 y가 동시에 일어날 확률</center>\n",
    "\n",
    "**<center>PMI 값이 높을 수록 관련성이 높다.</center>**\n",
    "\n",
    "---\n",
    "동시발생 행렬과 비교할 때, PMI는 $P(x)P(y)$를 분모로 나눠줌으로서 <u>단어가 단독으로 출현하는 횟수를 고려</u> 하여 관련성을 산출한다.\n",
    "\n",
    "따라서 고빈도 단어인 `the` 와 다른 단어와의 PMI 점수는 낮아진다.\n",
    "\n",
    "PMI에도 한 가지 문제가 있는데 두 단어의 동시발생 횟수가 0이면 $log_2{0} = -\\infty$ 가 되어버림\n",
    "\n",
    "따라서 실제 사용할 때는 **양의 상호정보량** <sup>Positive PMI</sup> (**PPMI**)를 사용한다.\n",
    "\n",
    "$$PPMI(x,y) = max(0,PMI(x,y))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T19:15:46.295427Z",
     "start_time": "2019-12-27T19:15:46.287092Z"
    }
   },
   "outputs": [],
   "source": [
    "# 동시발생 행렬을 PPMI 행렬로 변환하는 함수\n",
    "def ppmi(C, verbose=False, eps=1e-8):\n",
    "    M = np.zeros_like(C, dtype = np.float32)\n",
    "    N = np.sum(C) # return scalar\n",
    "    S = np.sum(C,axis=0) # return array, row 단위로 합치기\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2((C[i,j] * N) / (S[i] * S[j]) + eps)\n",
    "            M[i,j] = max(0,pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                k = total//100 # integer division\n",
    "                if (k !=0) & (cnt % k == 0):\n",
    "                    print(\"%.1f%% 완료\" % (100*cnt/total),end='\\r')            \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T19:15:46.674027Z",
     "start_time": "2019-12-27T19:15:46.663227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "W = ppmi(co_matrix)\n",
    "np.set_printoptions(precision=3)\n",
    "print(co_matrix)\n",
    "print(\"-\"*50)\n",
    "print(\"PPMI\")\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T17:43:36.437478Z",
     "start_time": "2019-12-27T17:43:36.431498Z"
    }
   },
   "source": [
    "그러나 말뭉치의 어휘 수가 증가함에 따라 각 단어 벡터의 차원 수도 증가한다는 문제가 여전히 존재한다.\n",
    "\n",
    "이 문제에 대처하고자 사용하는 기법이 벡터의 차원 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 차원감소\n",
    "\n",
    "`dimensionality reduction` \n",
    "\n",
    "중요한 정보는 유지하면서 차원을 줄이는 것이 핵심\n",
    "\n",
    "**특잇값분해**<sup>Singular Value Decomposition </sup> **(SVD)** 를 이용할 것\n",
    "\n",
    "SVD는 임의의 행렬을 세 행렬의 곱으로 분해한다.\n",
    "$$X = USV^T$$\n",
    "<center>U와 V는 직교 행렬 (orthogonal matrix). 두 열벡터는 서로 직교한다. </center>\n",
    "<center>S는 대각행렬 (diagonal matrix). 대각성분 외에는 모두 0인 행렬 </center>\n",
    "\n",
    "- U 행렬은 '단어 공간'으로 취급\n",
    "- S 행렬은 대각선분에 특잇값 (singular value)가 큰 순서로 나열되어 있음. 특잇값이란, 해당 축의 중요도라고 간주할 수 있다.\n",
    "\n",
    "**중요도가 낮은 원소는 특잇값이 작은 원소이며 이 원소들을 깎아내리는 방식이 SVD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD에 의한 차원감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T18:05:56.092631Z",
     "start_time": "2019-12-27T18:05:56.080975Z"
    }
   },
   "outputs": [],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size,window_size=1)\n",
    "W = ppmi(C)\n",
    "\n",
    "U,S,V = np.linalg.svd(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T18:08:49.009222Z",
     "start_time": "2019-12-27T18:08:49.000112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      "[ 3.409e-01  0.000e+00 -1.205e-01 -3.886e-16 -9.323e-01 -1.110e-16\n",
      " -2.426e-17]\n"
     ]
    }
   ],
   "source": [
    "print(C[0]) # 동시발생 행렬\n",
    "print(W[0]) # PPMI 행렬\n",
    "print(U[0]) #SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T18:11:02.586081Z",
     "start_time": "2019-12-27T18:11:02.578918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.409e-01,  0.000e+00, -1.205e-01, -3.886e-16, -9.323e-01,\n",
       "        -1.110e-16, -2.426e-17],\n",
       "       [ 0.000e+00, -5.976e-01,  0.000e+00,  1.802e-01,  0.000e+00,\n",
       "        -7.812e-01,  0.000e+00],\n",
       "       [ 4.363e-01, -5.551e-17, -5.088e-01, -2.220e-16,  2.253e-01,\n",
       "        -1.388e-17, -7.071e-01],\n",
       "       [ 1.110e-16, -4.978e-01,  2.776e-17,  6.804e-01, -1.110e-16,\n",
       "         5.378e-01,  7.467e-17],\n",
       "       [ 4.363e-01, -3.124e-17, -5.088e-01, -1.600e-16,  2.253e-01,\n",
       "        -1.302e-17,  7.071e-01],\n",
       "       [ 7.092e-01, -3.124e-17,  6.839e-01, -1.600e-16,  1.710e-01,\n",
       "        -1.302e-17,  2.314e-17],\n",
       "       [-1.665e-16, -6.285e-01, -4.163e-17, -7.103e-01,  2.220e-16,\n",
       "         3.169e-01, -9.614e-17]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "희소벡터가 SVD에 의해 밀집벡터로 변했다.\n",
    "\n",
    "밀집벡터의 차원을 감소시키려면, 2차원 벡터로 줄이려면 단순히 처음의 두 원소를 꺼내면 됨!\n",
    "\n",
    "```python\n",
    "print(U[0, :2])\n",
    "# [0.341 0.   ]\n",
    "```\n",
    "\n",
    "(중요도 순으로 가장 중요한 벡터, 그다음 중요한 벡터 일 것이므로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T18:17:17.700124Z",
     "start_time": "2019-12-27T18:17:17.507878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 2차원 단어간 관련성 그래프 그려보기\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))# 그래프 좌표 (x,y)지점에 word 텍스트 넣기\n",
    "    \n",
    "plt.scatter(U[:,0], U[:,1],alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T18:13:46.569744Z",
     "start_time": "2019-12-27T18:13:46.563310Z"
    }
   },
   "source": [
    "## PTB 데이터셋\n",
    "\n",
    "**펜 트리뱅크**<sup>Penn Treebank</sup> (PTB)\n",
    "\n",
    "주어진 기법의 품질을 측정하는 벤치마크로 자주 이용됨\n",
    "\n",
    "데이터 다운로드: http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T18:24:49.584367Z",
     "start_time": "2019-12-27T18:24:46.204581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.train.txt ... \n",
      "Done\n",
      "corpus size: 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id['car']: 3856\n",
      "word_to_id['happy']: 4428\n",
      "word_to_id['lexus']: 7426\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "print('corpus size:', len(corpus))\n",
    "print('corpus[:30]:', corpus[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word[0])\n",
    "print('id_to_word[1]:', id_to_word[1])\n",
    "print('id_to_word[2]:', id_to_word[2])\n",
    "print()\n",
    "print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T19:28:12.424361Z",
     "start_time": "2019-12-27T19:28:12.416309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'five'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T19:25:38.416193Z",
     "start_time": "2019-12-27T19:16:00.773131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting  co-occurrence ...\n",
      "calculating PPMI ...\n",
      "calculating SVD ...\n",
      "\n",
      "[query]you\n",
      " i: 0.6631186008453369\n",
      " anybody: 0.5714071989059448\n",
      " do: 0.5469673275947571\n",
      " we: 0.5438133478164673\n",
      " else: 0.5011815428733826\n",
      "\n",
      "[query]year\n",
      " month: 0.6628412008285522\n",
      " next: 0.6407493352890015\n",
      " earlier: 0.6264203786849976\n",
      " quarter: 0.621600866317749\n",
      " last: 0.591331958770752\n",
      "\n",
      "[query]car\n",
      " auto: 0.651628851890564\n",
      " truck: 0.5045391321182251\n",
      " luxury: 0.47440305352211\n",
      " corsica: 0.46512120962142944\n",
      " domestic: 0.44679921865463257\n",
      "\n",
      "[query]toyota\n",
      " motor: 0.754572331905365\n",
      " motors: 0.6863991022109985\n",
      " mazda: 0.5960850715637207\n",
      " nissan: 0.5876754522323608\n",
      " lexus: 0.5664078593254089\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('counting  co-occurrence ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('calculating PPMI ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "try:\n",
    "    # truncated SVD (SVD에 비해 훨씬 빠르다)\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=None)\n",
    "except ImportError:\n",
    "    # SVD (slow)\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T19:29:19.204519Z",
     "start_time": "2019-12-27T19:29:18.331078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query]love\n",
      " dream: 0.5101369619369507\n",
      " mouth: 0.4341052770614624\n",
      " wind: 0.4198186695575714\n",
      " remember: 0.41060158610343933\n",
      " write: 0.40879327058792114\n",
      "\n",
      "[query]sad\n",
      " helpful: 0.5438684225082397\n",
      " boveri: 0.5142133235931396\n",
      " laff: 0.5117758512496948\n",
      " reflection: 0.5109156966209412\n",
      " delicate: 0.49580439925193787\n",
      "fuck 를 찾을 수 없습니다.\n",
      "\n",
      "[query]mother\n",
      " volokh: 0.5899347066879272\n",
      " dissent: 0.5792067646980286\n",
      " birthday: 0.5663775205612183\n",
      " daughter: 0.5387136340141296\n",
      " predecessor: 0.5350900888442993\n",
      "\n",
      "[query]computer\n",
      " software: 0.7458308935165405\n",
      " computers: 0.7051543593406677\n",
      " desktop: 0.6708274483680725\n",
      " optical: 0.6138895750045776\n",
      " hand-held: 0.5713750123977661\n"
     ]
    }
   ],
   "source": [
    "querys = ['love', 'sad', 'fuck', 'mother','computer']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
