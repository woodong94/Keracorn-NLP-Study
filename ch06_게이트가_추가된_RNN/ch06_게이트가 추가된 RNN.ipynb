{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5장의 RNN은 과거의 정보를 기억할 수 있었지만 성능이 좋지 못하다.   \n",
    "주된 원인은 시계열 데이터에서 시간적으로 멀리 떨어진 장기 의존 관계를 잘 학습할 수 없다는 것.  통칭 `Long Term Dependency Problem`! \n",
    "\n",
    "이번 장에서는 `LSTM`이나 `GRU`와 같은 게이트가 추가된 RNN을 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN의 문제점\n",
    "\n",
    "RNN은 시계열 데이터의 장기 의존 관계를 학습하지 못한다.    \n",
    "그 원인은 BPTT<sup>Backpropagation Through Time</sup>에서 기울기 소실 `Vanishing Gradients` 혹은 기울기 폭발 `Exploding Gradients` 이 일어나기 때문!\n",
    "\n",
    "wowwow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기 소실 또는 기울기 폭발\n",
    "\n",
    "<img src = \"../imgs/fig 6-3.png\" width = \"500\" align = \"center\">\n",
    "\n",
    "5장에서 다뤘던 RNNLM이 `?`를 `Tom`으로 올바르게 예측하기 위해서는 현재 맥락에서 \n",
    "1. Tom이 방에서 TV를 보고 있음\n",
    "2. 그 방에 Mary가 들어옴 \n",
    "\n",
    "의 정보들을 기억해야 한다.\n",
    "\n",
    "BUT 현재 RNN계층에서는 기울기 소실 혹은 기울기 폭발이 일어나서 최종 목적지 Tom까지 가중치 매개변수가 도달하지 않게 된다.   \n",
    "**학습이 안 되는 것!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기 소실과 기울기 폭발의 원인\n",
    "\n",
    "<img src = \"../imgs/fig 6-5.png\" width = \"700\" align = \"center\">\n",
    "\n",
    "\n",
    "- T 번째 정답 레이블은 Tom\n",
    "- 기울기는 차례로 `tanh`, `+`, `MatMul`(행렬 곱) 연산을 통과한다\n",
    "\n",
    "\n",
    "    1. `+`의 역전파는 상류에서 전해지는 기울기를 하류로 그대로 흘려보낸다\n",
    "\n",
    "    2. `tanh`는 역전파 시에 $1-y^2$로 흘러간다 이때 값은 1 이하이고 x가 0으로부터 멀어질 수록 작아진다\n",
    "    \n",
    "        - 이는 즉, 역전파 시에 `tanh`를 만날때마다 기울기가 매우 작아진다는 것!\n",
    "        - `tanh`를 T번 통과하면 기울기도 T번 반복해서 작아짐!\n",
    "        ==> **ReLU 함수를 이용해서 개선!**\n",
    "\n",
    "    3. 역전파 시에 기울기는 MatMul을 만날 때마다 어떻게 변할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 실험 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 2 # 미니배치 크기\n",
    "H = 3 # 은닉 상태 벡터 차원 수 \n",
    "T = 20 # 시계열 데이터의 길이 \n",
    "\n",
    "dh = np.ones((N,H))\n",
    "np.random.seed(3) # 재현할 수 있도록 난수 고정\n",
    "Wh = np.random.randn(H,H)\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.matmul(dh, Wh.T) # 역전파의 노드 수 만큼 dh를 갱신\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N # dh의 크기 : L2 norm 사용\n",
    "    norm_list.append(norm) # 각 단계에서 dh의 크기를 norm_list에 추가\n",
    "    \n",
    "plt.plot(norm_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기가 시간에 비례해 지수적으로 증가함! 이것이 바로 `Exploding Gradients`\n",
    "\n",
    "기울기 폭발이 일어나면 Overflow를 일으켜 결국 NaN같은 값을 발생시킨다. 신경망 학습이 제대로 수행 안 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 실험 2\n",
    "\n",
    "```python\n",
    "# Wh = np.random.randn(H,H) # 변경 전\n",
    "Wh = np.random.randn(H,H) * 0.5 # 변경 후\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 2 # 미니배치 크기\n",
    "H = 3 # 은닉 상태 벡터 차원 수 \n",
    "T = 20 # 시계열 데이터의 길이 \n",
    "\n",
    "dh = np.ones((N,H))\n",
    "np.random.seed(3) # 재현할 수 있도록 난수 고정\n",
    "#Wh = np.random.randn(H,H) # 변경 전\n",
    "Wh = np.random.randn(H,H) * 0.5 # 변경 후\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.matmul(dh, Wh.T) # 역전파의 노드 수 만큼 dh를 갱신\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N # dh의 크기 : L2 norm 사용\n",
    "    norm_list.append(norm) # 각 단계에서 dh의 크기를 norm_list에 추가\n",
    "    \n",
    "plt.plot(norm_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반대로 기울기가 지수적으로 감소함! 이것이 `Vanishinng Gradients`\n",
    "\n",
    "기울기 소실이 일어나면 기울기가 매우 빠르게 작아져 가중치 매개변수가 더 이상 갱신되지 않아 학습 효과가 발생하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 소실 혹은 기울기 폭발 원인\n",
    "\n",
    "이러한 지수적인 변화가 일어나는 이뉴는 행렬 Wh를 T번 반복해서 곱했기 때문\n",
    "\n",
    "Wh가 스칼라라면? \n",
    "   -  1보다 크면 지수적으로 증가하고, 1보다 작으면 지수적으로 감소\n",
    "\n",
    "Wh가 스칼라가 아니라 행렬이라면?\n",
    "   - 행렬의 특잇값이 척도가 된다. \n",
    "   - 행렬의 특잇값이란, 간단히 말해 데이터가 얼마나 퍼져있는 지를 나타냄.\n",
    "   - 특잇값의 최댓값이 1보다 크면 지수적으로 증가하고 1보다 작으면 지수적으로 감소할 가능성이 높음..! (안 그럴 수도)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기 폭발 대책\n",
    "\n",
    "기울기 폭발의 대책으로 전통적인 기법. 기울기 클리핑 `Gradients clipping`.\n",
    "\n",
    "$$ {if}\\ \\lVert \\hat{g}\\rVert \\ge threshold : $$\n",
    "\n",
    "$$\\hat{g} = \\frac{threshold}{\\lVert \\hat{g}\\rVert}\\hat{g}$$\n",
    "\n",
    "- $\\hat{g}$ ; 기울기 통칭\n",
    "- $\\lVert \\hat{g}\\rVert$ : L2 norm \n",
    "\n",
    "**기울기의 l2 norm이 threshold를 초과하면 두 번째 줄의 수식처럼 기울기를 수정한다. 기울기 깎음.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clipping 전'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array([[3.40688484, 0.64673198, 8.64119669],\n",
       "        [2.90872446, 7.41082406, 1.58033655],\n",
       "        [6.94963435, 8.41419619, 7.27152079]]),\n",
       " array([[3.59107525, 7.26689751, 1.39467124],\n",
       "        [3.13819115, 4.19582757, 8.77212039],\n",
       "        [1.53740209, 8.8012479 , 7.98964319]])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'clipping 후'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.67320956, 0.12779597, 1.70752359],\n",
       "        [0.57477174, 1.46439866, 0.31227873],\n",
       "        [1.37326634, 1.66266768, 1.43687196]]),\n",
       " array([[0.70960608, 1.43595839, 0.27559077],\n",
       "        [0.62011497, 0.82910675, 1.73339446],\n",
       "        [0.30379477, 1.73915013, 1.57877487]])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dW1 = np.random.rand(3,3) * 10\n",
    "dW2 = np.random.rand(3,3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0 #threshold\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "        \n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if total_norm >= max_norm :\n",
    "        for grad in grads:\n",
    "            grad *= rate\n",
    "            \n",
    "display(\"clipping 전\", grads)\n",
    "clip_grads(grads,max_norm)\n",
    "print()\n",
    "display(\"clipping 후\", grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기울기 소실과 LSTM\n",
    "\n",
    "기울기 소실 문제를 해결하기 위해서는 RNN 계층을 갈아엎어야함! \n",
    "\n",
    "==> **게이트가 추가된 RNN**. 대표적인 신경망에는 LSTM과 GRU가 있다.\n",
    "\n",
    "이번 장에서는 LSTM에 집중하고 도식은 간소화하여 설명함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM의 인터페이스\n",
    "\n",
    "<img src = \"../imgs/fig 6-11.png\" width = \"600\" align = \"center\">\n",
    "\n",
    "- LSTM 계층의 인터페이스에는 **c**라는 경로가 있다\n",
    "    - **이 c은 `memory cell` 혹은 `cell` 이라고 하며, LSTM 전용의 기억 매커니즘이다.**\n",
    "    - 기억 셀은 LSTM 계층 내에서만 작동. LSTM 계층 내에서만 완결되고, 다른 계층으로는 출력하지 않음.\n",
    "    \n",
    "    \n",
    "- LSTM의 은닉 상태 h는 RNN 계층과 마찬가지로 가른 계층으로 출력됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 계층 조립하기\n",
    "\n",
    "- LSTM에는 시각 t에서의 LSTM의 기억이 저장된 **기억 셀 $c_t$가 있다.** \n",
    "- 이때 c에는 과거로부터 시각 t까지에 필요한 모든 정보가 저장되어 있다고 가정하자.\n",
    "- 이 모든 정보를 담고 외부 계층에 은닉 상태 $h_t$를 출력한다. (이때 출력값은 기억 셀을 tanh함수로 변환한 값)\n",
    "\n",
    " <center> 기억 셀 $c_t$는 입력 ($c_{t-1}, h_{t-1}, x_t$)으로부터 어떤 계산을 거쳐 구해진다! </center>\n",
    "\n",
    "#### <center> 핵심은 갱신된 $c_t$를 활용해 은닉 상태 $h_t$를 계산한다는 것 </center>\n",
    "\n",
    "$$h_t = tanh(c_t)$$\n",
    "\n",
    "---\n",
    "\n",
    "- 또한 LSTM 에는 `게이트`라는 기능이 존재한다\n",
    "    - 열기/닫기\n",
    "    - 어느 정도 열지 조절 가능 openness! (0.7 or 0.2...)\n",
    "        - 게이트의 열림 상태는 0.0-1.0 사이의 실수로 나타난다\n",
    "        - sigmoid 함수\n",
    "    - **LSTM 은 이러한 \"게이트의 열림 정도\"를 <u>데이터로부터 자동으로 학습한다</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output 게이트 (LSTM의 출력 부분)\n",
    "\n",
    "<img src = \"../imgs/fig 6-15.png\" width = \"300\" align = \"center\">\n",
    "\n",
    "\n",
    "은닉상태 $h_t$ = $tanh(c_t)$\n",
    "\n",
    "- 게이트는 $tanh(c_t)$ 의 각 원소에 대해 **그것이 다음 시각의 은닉 상태에 얼마나 중요한가**를 조정한다\n",
    "- 이 게이트는 다음 은닉 상태 $h_t$의 출력을 담당하는 게이트이므로 `output 게이트` 라고 부른다.\n",
    "\n",
    "\n",
    "<img src = \"../imgs/e 6-1.png\" width = \"200\" align = \"center\">\n",
    "\n",
    "1.  output 게이트의 열림 상태는 입력 $x_t$ 이전 상태 $h_{t-1}$로부터 계산한다 \n",
    "- o : output\n",
    "- $\\sigma$ : sigmoid\n",
    "- $W^{(o)}$ : 게이트 가중치\n",
    "\n",
    "2. 계산을 거친 뒤 시그모이드 함수를 거쳐 출력 게이트의 출력 o를 구한다.\n",
    "\n",
    "3. 마지막으로 이 o와 $tanh(c_t)$의 원소 별 곱을 $h_t$로 출력한다.\n",
    "    - 원소 별 곱이란 `아다마르 곱` (Hadamard product) 이라고도 한다.\n",
    "    - $\\odot$\n",
    "\n",
    "<img src = \"../imgs/e 6-2.png\" width = \"150\" align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고]\n",
    "\n",
    "- tanh\n",
    "    - -1.0 -1.0의 실수.\n",
    "    - 인코딩된 정보의 \"강약 정도\"라고 해석\n",
    "    - **실질적인 정보를 지니는 데이터에 사용됨**\n",
    "- sigmoid \n",
    "    - 0.0-1.0의 실수. \n",
    "    - 데이터를 얼마만큼 통과시킬 지를 정하는 비율\n",
    "    - **게이트에서 주로 사용됨**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forget 게이트 (망각 게이트)\n",
    "\n",
    "<img src = \"../imgs/fig 6-16.png\" width = \"300\" align = \"center\">\n",
    "\n",
    "- $c_{t-1}$의 기억 정보 중에서 불필요한 정보를 잊게 해주는 게이트\n",
    "\n",
    "<img src = \"../imgs/e 6-3.png\" width = \"200\" align = \"center\">\n",
    "\n",
    "- f : forget 게이트의 출력\n",
    "- 이 f와 이전 기억 셀인 $c_{t-1}$과의 원소 별 곱, 즉 $c_{t} = {f}\\odot{c_{t-1}}$ 를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 기억 셀\n",
    "\n",
    "- forget 게이트를 거치면서 이전 계층의 기억 셀로부터 지워야 할 정보가 삭제되었다\n",
    "- but 이 상태로는 기억 셀 c가 잊는 것 밖에 하지 못함. \n",
    "- **새로 기억할 정보를 기억 셀 c에 추가해야됨.**\n",
    "\n",
    "<img src = \"../imgs/fig 6-17.png\" width = \"300\" align = \"center\">\n",
    "\n",
    "- tanh 노드가 계산한 결과가 이전 시각의 기억 셀 $c_{t-1}$에 더해진다\n",
    "- tanh 노드는 게이트가 아니고! 새로운 정보를 기억 셀에 추가해주는 역할\n",
    "\n",
    "<img src = \"../imgs/e 6-4.png\" width = \"250\" align = \"center\">\n",
    "\n",
    "- g가 이전 시각 기억 셀 $c_{t-1}$에 더해짐으로써 새로운 기억이 생겨난다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input 게이트 (입력 게이트)\n",
    "\n",
    "<img src = \"../imgs/fig 6-18.png\" width = \"300\" align = \"center\">\n",
    "\n",
    "- input 게이트는 각 원소가 새로 추가되는 정보로써의 가치가 얼마나 큰 지 판단. 가중 or 축소\n",
    "\n",
    "<img src = \"../imgs/e 6-5.png\" width = \"200\" align = \"center\">\n",
    "\n",
    "- i와 g의 원소별 곱 결과를 기억 셀에 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM의 기울기 흐름\n",
    "\n",
    "**RNN과 다르게 기울기 소실이 일어나지 않는 이유**\n",
    "\n",
    "똑같은 가중치 행렬을 사용하여 행렬 곱을 반복하여 기울기 소실 혹은 기울기 폭발을 일으켰던 RNN과 다르게,   \n",
    "매 시각 다른 게이트 값을 이용해 원소 별 곱을 계산. 곱셈의 효과가 누적되지 않는다.\n",
    "\n",
    "<요약>\n",
    "1. 행렬 곱 아닌 원소별 곱(아다마르 곱)\n",
    "2. 매 시각 다른 게이트 값 사용 (곱셈 누적 x)\n",
    "\n",
    "LSTM = Long Short-Term Memory, **단기 기억**을 **긴 시간 지속**할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 구현\n",
    "\n",
    "<img src = \"../imgs/e 6-6.png\" width = \"200\" align = \"center\">\n",
    "<center>$xW_x + hW_h + b$ 형태의 아핀 변환 (행렬 변환과 평행 이동을 결합한 형태)</center>\n",
    "\n",
    "---\n",
    "\n",
    "#### <center>위 4개의 식은 하나의 형태로 표현 가능하다</center>\n",
    "\n",
    "$$x_t W_x^{(f)} + h_{t-1} W_h^{(f)} + b^{(f)} $$\n",
    "$$x_t W_x^{(g)} + h_{t-1} W_h^{(g)} + b^{(g)} $$\n",
    "$$x_t W_x^{(i)} + h_{t-1} W_h^{(i)} + b^{(i)} $$\n",
    "$$x_t W_x^{(o)} + h_{t-1} W_h^{(o)} + b^{(o)} $$\n",
    "\n",
    "<img src = \"../imgs/fig 6-20 fixed.png\" width = \"400\" align = \"center\">\n",
    "\n",
    "#### <center>*** 4번 수행하던 아핀 변환을 1회의 계산으로 가능하게 함 ***</center> \n",
    "\n",
    "\n",
    "---\n",
    "그 외 수식\n",
    "\n",
    "<img src = \"../imgs/e 6-7.png\" width = \"150\" align = \"center\">\n",
    "<img src = \"../imgs/e 6-8.png\" width = \"150\" align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"../imgs/fig 6-21.png\" width = \"600\" align = \"center\">\n",
    "\n",
    "- 처음 4개 분의 아핀 변환을 한꺼번에 수행\n",
    "- slice 노드를 통해 그 4개의 결과를 꺼냄 ( f g i o )\n",
    "- slice 노드 다음에 활성화 함수 (시그모이드 or tanh)를 거친다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    # 초기화 코드\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None # 순전파 결과 보관용\n",
    "    \n",
    "    # 순전파\n",
    "    def forward(self, x, h_prev, c_prev): # 현시각의 입력, 이전 시각의 은닉 상태, 이전 시각의 기억 셀\n",
    "        Wx, Wh, b = self.params \n",
    "        N, H = h_prev.shape \n",
    "        \n",
    "        A = np.matmul(x, Wx) + np.matmul(h_prev, Wh) + b # 4개의 아핀 변환 결과 동시 처리 4H 만큼\n",
    "        \n",
    "        # slice\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "   \n",
    "    # 역전파\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "    \n",
    "        ds = dc_next + (dh_next * o) * (1 - np.tanh(c_next) ** 2)\n",
    "        \n",
    "        dc_prev = ds * f\n",
    "        \n",
    "        # 게이트 \n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "        \n",
    "        di *= i * (1 - i) \n",
    "        df *= f * (1 - f) \n",
    "        do *= o * (1 - o) \n",
    "        dg *= (1 - g ** 2) \n",
    "        \n",
    "        \n",
    "        dA = np.hstack((df, dg, di, do)) # 4개의 행렬 연결\n",
    "        \n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis = 0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time LSTM 구현\n",
    "\n",
    "T개분의 시계열 데이터 한꺼번에 처리하는 계층\n",
    "\n",
    "<img src = \"../imgs/fig 6-24.png\" width = \"600\" align = \"center\">\n",
    "\n",
    "<img src = \"../imgs/fig 6-25.png\" width = \"600\" align = \"center\">\n",
    "\n",
    "- RNN과 마찬가지로 Truncated BPTT 학습\n",
    "    - 역전파의 연결을 적당한 길이로 끊는다\n",
    "    - **`순전파의 흐름은 유지!!`**\n",
    "    - 은닉 상태와 기억 셀을 인스턴스 변수로 유지하여 다음번 forward가 불렸을 때 이전 시각부터 시작할 수 있도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    # 초기화 코드\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype = 'f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeors((N,H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c= np.zeors((N,H), dtype='f')\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:,t,:] = self.h\n",
    "            \n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)): # 역전파라서 reversed\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layㅁer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 을 사용한 언어 모델\n",
    "\n",
    "<img src = \"../imgs/fig 6-26.png\" width = \"600\" align = \"center\">\n",
    "\n",
    "RNN 혹은 LSTM. 신경망만 다르게 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from common.time_layers import *\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Rnnlm:\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')  # Xavier 초기화\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')  # Xavier 초기화\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_lyaer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기 리스트에 모음\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "\n",
    "    # 문장 생성\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n",
    "\n",
    "    # 매개변수 읽기 / 쓰기\n",
    "    def save_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            pickle.dump(self.params, f)\n",
    "\n",
    "    def load_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, \"rb\") as f:\n",
    "            self.params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 10001.13\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 6[s] | 퍼플렉서티 3104.35\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 11[s] | 퍼플렉서티 1256.38\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 18[s] | 퍼플렉서티 998.92\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 24[s] | 퍼플렉서티 795.90\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 30[s] | 퍼플렉서티 692.68\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 36[s] | 퍼플렉서티 653.10\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 41[s] | 퍼플렉서티 613.26\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 46[s] | 퍼플렉서티 586.16\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 51[s] | 퍼플렉서티 592.12\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 56[s] | 퍼플렉서티 514.07\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 61[s] | 퍼플렉서티 487.43\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 67[s] | 퍼플렉서티 447.01\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 73[s] | 퍼플렉서티 457.47\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 78[s] | 퍼플렉서티 464.87\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 84[s] | 퍼플렉서티 390.11\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 89[s] | 퍼플렉서티 349.28\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 94[s] | 퍼플렉서티 408.34\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 99[s] | 퍼플렉서티 407.41\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 104[s] | 퍼플렉서티 338.00\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 109[s] | 퍼플렉서티 349.42\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 114[s] | 퍼플렉서티 345.52\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 119[s] | 퍼플렉서티 329.80\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 124[s] | 퍼플렉서티 326.58\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 128[s] | 퍼플렉서티 300.20\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 133[s] | 퍼플렉서티 312.72\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 138[s] | 퍼플렉서티 297.62\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 144[s] | 퍼플렉서티 319.52\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 149[s] | 퍼플렉서티 286.29\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 154[s] | 퍼플렉서티 261.18\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 159[s] | 퍼플렉서티 337.24\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 163[s] | 퍼플렉서티 316.60\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 168[s] | 퍼플렉서티 285.29\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 173[s] | 퍼플렉서티 269.20\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 178[s] | 퍼플렉서티 227.93\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 183[s] | 퍼플렉서티 251.57\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 188[s] | 퍼플렉서티 259.33\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 193[s] | 퍼플렉서티 223.49\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 198[s] | 퍼플렉서티 232.39\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 203[s] | 퍼플렉서티 219.84\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 208[s] | 퍼플렉서티 243.74\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 212[s] | 퍼플렉서티 225.83\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 218[s] | 퍼플렉서티 233.43\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 223[s] | 퍼플렉서티 224.51\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 228[s] | 퍼플렉서티 207.65\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 233[s] | 퍼플렉서티 255.50\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 238[s] | 퍼플렉서티 228.31\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 242[s] | 퍼플렉서티 231.28\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 247[s] | 퍼플렉서티 244.96\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 252[s] | 퍼플렉서티 229.98\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 257[s] | 퍼플렉서티 195.80\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 263[s] | 퍼플렉서티 227.07\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 268[s] | 퍼플렉서티 208.92\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 273[s] | 퍼플렉서티 199.20\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 278[s] | 퍼플렉서티 170.24\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 283[s] | 퍼플렉서티 194.52\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 288[s] | 퍼플렉서티 230.31\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 293[s] | 퍼플렉서티 208.80\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 298[s] | 퍼플렉서티 199.67\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 303[s] | 퍼플렉서티 191.15\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 308[s] | 퍼플렉서티 162.64\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 313[s] | 퍼플렉서티 160.15\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 318[s] | 퍼플렉서티 189.64\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 323[s] | 퍼플렉서티 172.85\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 328[s] | 퍼플렉서티 179.41\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 333[s] | 퍼플렉서티 223.50\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 338[s] | 퍼플렉서티 211.91\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 340[s] | 퍼플렉서티 222.20\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 345[s] | 퍼플렉서티 204.96\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 350[s] | 퍼플렉서티 192.56\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 355[s] | 퍼플렉서티 178.72\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 360[s] | 퍼플렉서티 160.71\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 365[s] | 퍼플렉서티 153.63\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 370[s] | 퍼플렉서티 161.23\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 375[s] | 퍼플렉서티 179.18\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 380[s] | 퍼플렉서티 193.26\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 385[s] | 퍼플렉서티 200.66\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 390[s] | 퍼플렉서티 186.25\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 395[s] | 퍼플렉서티 186.32\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 400[s] | 퍼플렉서티 178.68\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 405[s] | 퍼플렉서티 185.90\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 410[s] | 퍼플렉서티 187.63\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 415[s] | 퍼플렉서티 169.12\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 420[s] | 퍼플렉서티 140.62\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 425[s] | 퍼플렉서티 172.66\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 430[s] | 퍼플렉서티 198.73\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 435[s] | 퍼플렉서티 155.28\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 440[s] | 퍼플렉서티 169.36\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 445[s] | 퍼플렉서티 157.32\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 450[s] | 퍼플렉서티 164.25\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 455[s] | 퍼플렉서티 158.87\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 460[s] | 퍼플렉서티 158.06\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 465[s] | 퍼플렉서티 168.09\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 470[s] | 퍼플렉서티 174.68\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 475[s] | 퍼플렉서티 175.51\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 480[s] | 퍼플렉서티 155.69\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 485[s] | 퍼플렉서티 139.14\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 490[s] | 퍼플렉서티 189.57\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 495[s] | 퍼플렉서티 181.89\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 500[s] | 퍼플렉서티 165.32\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 505[s] | 퍼플렉서티 155.38\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 510[s] | 퍼플렉서티 130.50\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 515[s] | 퍼플렉서티 151.80\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 520[s] | 퍼플렉서티 160.49\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 525[s] | 퍼플렉서티 135.25\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 530[s] | 퍼플렉서티 132.07\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 535[s] | 퍼플렉서티 136.33\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 541[s] | 퍼플렉서티 146.26\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 546[s] | 퍼플렉서티 146.18\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 551[s] | 퍼플렉서티 145.95\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 556[s] | 퍼플렉서티 146.38\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 561[s] | 퍼플렉서티 132.11\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 566[s] | 퍼플렉서티 166.79\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 571[s] | 퍼플렉서티 147.41\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 576[s] | 퍼플렉서티 155.14\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 581[s] | 퍼플렉서티 164.58\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 587[s] | 퍼플렉서티 154.73\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 592[s] | 퍼플렉서티 134.15\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 597[s] | 퍼플렉서티 157.09\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 602[s] | 퍼플렉서티 143.39\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 608[s] | 퍼플렉서티 130.16\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 613[s] | 퍼플렉서티 112.29\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 618[s] | 퍼플렉서티 121.89\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 623[s] | 퍼플렉서티 156.02\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 628[s] | 퍼플렉서티 143.07\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 633[s] | 퍼플렉서티 134.08\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 638[s] | 퍼플렉서티 135.52\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 643[s] | 퍼플렉서티 111.70\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 648[s] | 퍼플렉서티 110.14\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 653[s] | 퍼플렉서티 131.15\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 658[s] | 퍼플렉서티 124.91\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 663[s] | 퍼플렉서티 122.56\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 668[s] | 퍼플렉서티 160.35\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 673[s] | 퍼플렉서티 154.08\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 674[s] | 퍼플렉서티 161.59\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 679[s] | 퍼플렉서티 144.21\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 684[s] | 퍼플렉서티 135.55\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 689[s] | 퍼플렉서티 129.76\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 694[s] | 퍼플렉서티 117.45\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 699[s] | 퍼플렉서티 106.96\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 705[s] | 퍼플렉서티 116.11\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 710[s] | 퍼플렉서티 127.27\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 715[s] | 퍼플렉서티 143.73\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 719[s] | 퍼플렉서티 151.09\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 724[s] | 퍼플렉서티 142.34\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 729[s] | 퍼플렉서티 143.81\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 735[s] | 퍼플렉서티 134.35\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 741[s] | 퍼플렉서티 139.85\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 745[s] | 퍼플렉서티 143.06\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 750[s] | 퍼플렉서티 125.97\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 756[s] | 퍼플렉서티 102.95\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 761[s] | 퍼플렉서티 126.39\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 766[s] | 퍼플렉서티 153.85\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 771[s] | 퍼플렉서티 116.74\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 776[s] | 퍼플렉서티 131.58\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 781[s] | 퍼플렉서티 114.37\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 786[s] | 퍼플렉서티 124.62\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 791[s] | 퍼플렉서티 117.84\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 796[s] | 퍼플렉서티 120.64\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 801[s] | 퍼플렉서티 127.88\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 806[s] | 퍼플렉서티 137.35\n",
      "| 에폭 3 |  반복 541 / 1327 | 시간 811[s] | 퍼플렉서티 136.63\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 816[s] | 퍼플렉서티 119.77\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 821[s] | 퍼플렉서티 106.14\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 826[s] | 퍼플렉서티 149.48\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 832[s] | 퍼플렉서티 144.29\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 837[s] | 퍼플렉서티 129.25\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 842[s] | 퍼플렉서티 121.29\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 847[s] | 퍼플렉서티 100.30\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 852[s] | 퍼플렉서티 120.00\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 857[s] | 퍼플렉서티 127.12\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 862[s] | 퍼플렉서티 108.03\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 867[s] | 퍼플렉서티 103.82\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 872[s] | 퍼플렉서티 104.50\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 877[s] | 퍼플렉서티 114.88\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 882[s] | 퍼플렉서티 117.73\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 887[s] | 퍼플렉서티 115.67\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 892[s] | 퍼플렉서티 121.21\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 897[s] | 퍼플렉서티 107.43\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 902[s] | 퍼플렉서티 131.02\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 907[s] | 퍼플렉서티 118.83\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 912[s] | 퍼플렉서티 128.02\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 918[s] | 퍼플렉서티 132.54\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 928[s] | 퍼플렉서티 124.01\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 935[s] | 퍼플렉서티 111.06\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 941[s] | 퍼플렉서티 128.70\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 950[s] | 퍼플렉서티 118.62\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 955[s] | 퍼플렉서티 104.14\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 961[s] | 퍼플렉서티 89.71\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 968[s] | 퍼플렉서티 96.01\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 974[s] | 퍼플렉서티 123.37\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 981[s] | 퍼플렉서티 115.08\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 990[s] | 퍼플렉서티 108.13\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 1001[s] | 퍼플렉서티 112.21\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 1012[s] | 퍼플렉서티 94.04\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 1022[s] | 퍼플렉서티 88.69\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 1032[s] | 퍼플렉서티 105.75\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 1042[s] | 퍼플렉서티 106.53\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 1052[s] | 퍼플렉서티 101.43\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 1061[s] | 퍼플렉서티 130.95\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 1073[s] | 퍼플렉서티 126.90\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 1076[s] | 퍼플렉서티 133.38\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 1084[s] | 퍼플렉서티 123.54\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 1091[s] | 퍼플렉서티 108.05\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 1099[s] | 퍼플렉서티 108.80\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 1108[s] | 퍼플렉서티 96.27\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 1117[s] | 퍼플렉서티 87.80\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 1124[s] | 퍼플렉서티 95.56\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 1130[s] | 퍼플렉서티 104.01\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 1137[s] | 퍼플렉서티 119.03\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 1147[s] | 퍼플렉서티 129.86\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 1156[s] | 퍼플렉서티 120.65\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 1165[s] | 퍼플렉서티 124.10\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 1171[s] | 퍼플렉서티 114.49\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 1177[s] | 퍼플렉서티 115.30\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 1186[s] | 퍼플렉서티 121.51\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 1195[s] | 퍼플렉서티 106.58\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 1205[s] | 퍼플렉서티 85.88\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 1212[s] | 퍼플렉서티 102.25\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 1219[s] | 퍼플렉서티 130.25\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 1227[s] | 퍼플렉서티 98.30\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 1232[s] | 퍼플렉서티 111.38\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 1238[s] | 퍼플렉서티 94.94\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 1246[s] | 퍼플렉서티 103.97\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 1256[s] | 퍼플렉서티 99.92\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 1262[s] | 퍼플렉서티 102.63\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 1269[s] | 퍼플렉서티 108.47\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 1277[s] | 퍼플렉서티 116.32\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 1286[s] | 퍼플렉서티 113.59\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 1292[s] | 퍼플렉서티 104.63\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 1300[s] | 퍼플렉서티 89.51\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 1309[s] | 퍼플렉서티 127.78\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 1316[s] | 퍼플렉서티 122.38\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 1322[s] | 퍼플렉서티 111.60\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 1329[s] | 퍼플렉서티 104.24\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 1335[s] | 퍼플렉서티 84.96\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 1340[s] | 퍼플렉서티 103.71\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 1345[s] | 퍼플렉서티 108.37\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 1350[s] | 퍼플렉서티 95.77\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 1355[s] | 퍼플렉서티 89.28\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 1360[s] | 퍼플렉서티 88.12\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 1365[s] | 퍼플렉서티 97.35\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 1370[s] | 퍼플렉서티 103.32\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 1375[s] | 퍼플렉서티 99.82\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 1379[s] | 퍼플렉서티 105.41\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 1384[s] | 퍼플렉서티 92.69\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 1389[s] | 퍼플렉서티 115.18\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 1394[s] | 퍼플렉서티 103.84\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 1399[s] | 퍼플렉서티 113.52\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 1405[s] | 퍼플렉서티 113.04\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 1409[s] | 퍼플렉서티 107.41\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 1414[s] | 퍼플렉서티 98.86\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 1420[s] | 퍼플렉서티 112.82\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 1425[s] | 퍼플렉서티 103.47\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 1430[s] | 퍼플렉서티 89.48\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 1435[s] | 퍼플렉서티 79.25\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 1440[s] | 퍼플렉서티 80.61\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 1445[s] | 퍼플렉서티 104.47\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 1450[s] | 퍼플렉서티 101.24\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 1455[s] | 퍼플렉서티 92.86\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 1460[s] | 퍼플렉서티 96.43\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 1465[s] | 퍼플렉서티 84.39\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 1470[s] | 퍼플렉서티 76.70\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 1475[s] | 퍼플렉서티 91.99\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 1480[s] | 퍼플렉서티 94.75\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 1485[s] | 퍼플렉서티 90.27\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 1490[s] | 퍼플렉서티 111.67\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 1495[s] | 퍼플렉서티 110.37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉시티:  136.2600433175287\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from rnnlm import Rnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN 은닉 상태 벡터의 원소 수 \n",
    "time_size = 35 # RNN 펼치는 크기\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:] # target\n",
    "\n",
    "# 모델 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "########################################\n",
    "# 1 - 기울기 클리핑 적용하여 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, \n",
    "            eval_interval=20) # 20번째 반복마다 퍼플렉시티 평가하라\n",
    "trainer.plot(ylim=(0,500))\n",
    "\n",
    "# 2 - 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test) # 모델 상태를 재설정하여 평가를 수행\n",
    "print(\"테스트 퍼플렉시티: \",ppl_test)\n",
    "\n",
    "# 3 - 학습 완료된 매개변수들을 파일로 저장\n",
    "model.save_params()\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉시티:  136.30010584700165\n"
     ]
    }
   ],
   "source": [
    "# 2 - 테스트 데이터로 평가\n",
    "ppl_test = eval_perplexity(model, corpus_test) # 모델 상태를 재설정하여 평가를 수행\n",
    "print(\"테스트 퍼플렉시티: \",ppl_test)\n",
    "\n",
    "# 3 - 학습 완료된 매개변수들을 파일로 저장\n",
    "model.save_params()\n",
    "########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNLM 추가 개선\n",
    "\n",
    "- 개선 포인트 3가지 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 계층 다층화\n",
    "\n",
    "많은 경우 LSTM을 2층, 3층 등으로 여러 개 쌓아 더 나은 정확도의 모델을 기대할 수 있다.\n",
    "\n",
    "<img src = \"../imgs/fig 6-29.png\" width = \"500\" align = \"center\">\n",
    "\n",
    "- 첫 번째 LSTM 계층의 은닉 상태가 두 번째 LSTM 계층에 입력된다\n",
    "- 구글 번역에서 사용하는 GNMT 모델은 LSTM 을 8층 쌓은 신경망!\n",
    "- **데이터의 개수에 따라 적절하게 쌓는 것이 중요하다**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout에 의한 overfitting 억제\n",
    "\n",
    "- 층을 깊게 쌓으면 정확한 모델을 얻을 수 있다는 장점이 있으나, `과적합 overfitting` 을 일으킬 수 있다!\n",
    "- 일반적으로 RNN 계열 모델이 더 과적합에 약하다\n",
    "- 그러므로 RNN계열 모델을 사용한다면 과적합 억제 방법을 적용시키는 것이 필수!\n",
    "\n",
    "---\n",
    "\n",
    "### overfitting 방지\n",
    "1. 훈련 데이터 양 늘리기\n",
    "2. 모델의 복잡도 줄이기\n",
    "\n",
    "3. 그 외) 모델 복잡도에 페널티를 주는 정규화 (normalization) 방식\n",
    "    - L2 정규화는 가중치가 너무 커지면 페널티를 부과한다 \n",
    "    - `Dropout`이 정규화의 일종임\n",
    "\n",
    "### Dropout\n",
    "\n",
    "**RNN 모델에 Dropout 계층을 어디에 삽입해야 할까?**\n",
    "\n",
    "<img src = \"../imgs/fig 6-32.png\" width = \"700\" align = \"center\">\n",
    "\n",
    "- 드롭아웃 계층을 시계열 방향으로 넣기\n",
    "    - **학습 시 시간의 흐름에 따라 정보가 사라질 수 있다**\n",
    "    - 흐르는 시간에 비례해 드롭아웃에 의한 노이즈가 축적된다..! NO!\n",
    "\n",
    "<img src = \"../imgs/fig 6-33.png\" width = \"600\" align = \"center\">\n",
    "\n",
    "- 드롭아웃 계층을 깊이 방향 넣기\n",
    "    - 시간 방향에 비례하여 정보 소실이 일어나지 않는다 \n",
    "    - 시간과 상관없이 독립적으로 영향주기\n",
    "    - **`Variational Dropout` : 시간 방향의 드롭아웃**\n",
    "    - <img src = \"../imgs/fig 6-34.png\" width = \"650\">\n",
    "    - 같은 계층의 드롭아웃끼지 같은 마스크를 공유함으로써 마스크가 고정된다 \n",
    "    - 정보를 잃게 되는 압버도 고정되므로, 일반적인 드롭아웃 때와 달리 정보가 지수적으로 손실되는 사태 막음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개선된 RNNLM 구현\n",
    "\n",
    "<img src = \"../imgs/fig 6-36.png\" width = \"300\" align = \"center\">\n",
    "\n",
    "- 개선점은 다음 세가지 \n",
    "\n",
    "    - LSTM 계층의 다층화\n",
    "    - 드롭아웃 사용 ( 깊이 방향 )\n",
    "    - 가중치 공유 ( Embedding 계층과 Affine 계층에서 가중치 공유 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650, hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')  # Xavier 초기화\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')  # Xavier 초기화\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')  # Xavier 초기화\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')  # Xavier 초기화\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        # affine_W = (rn(H, V) / np.sqrt(H)).astype('f') # embed와 공유할라공\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)  # 가중치 공유!!\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        # 모든 가중치와 기울기 리스트에 모음\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    # 문장 생성\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 5[s] | 퍼플렉서티 10000.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c4f411f3d0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n\u001b[0;32m---> 37\u001b[0;31m                 time_size=time_size, max_grad=max_grad)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google 드라이브/2020/Study/[2019.12-] Keracorn/Keracorn-NLP-Study/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# 기울기를 구해 매개변수 갱신\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 순전파 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 역전파 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google 드라이브/2020/Study/[2019.12-] Keracorn/Keracorn-NLP-Study/ch06/better_rnnlm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs, ts, train_flg)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google 드라이브/2020/Study/[2019.12-] Keracorn/Keracorn-NLP-Study/ch06/better_rnnlm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, xs, train_flg)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_flg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google 드라이브/2020/Study/[2019.12-] Keracorn/Keracorn-NLP-Study/common/time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google 드라이브/2020/Study/[2019.12-] Keracorn/Keracorn-NLP-Study/common/time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_prev, c_prev)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mc_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_prev\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google 드라이브/2020/Study/[2019.12-] Keracorn/Keracorn-NLP-Study/common/functions.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import config\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity, to_gpu\n",
    "from dataset import ptb\n",
    "from better_rnnlm import BetterRnnlm\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5 \n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf') # 무한대로 초기 설정\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
    "                time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티: ', ppl)\n",
    "\n",
    "    # 검증 데이터 퍼플렉시티가 best ppl 보다 낮으면 학습률을 1/4로 줄임\n",
    "    if best_ppl > ppl: \n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "## 퍼플렉시티 75!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
