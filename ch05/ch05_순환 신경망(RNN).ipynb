{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 살펴본 신경망은 피드포워드 유형의 신경망이다. 피드포워드란 흐름이 단방향을 신경망을 말한다.\n",
    "\n",
    "그러나 피드포워드 신경망은 **시계열 데이터의 성질(패턴)을 충분히 학습할 수 없다**는 커다란 단점이 있다.\n",
    "\n",
    "그래서 **순환 신경망 <sup>Recurrent Neural Network</sup> (RNN)** 이 등장하게 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 확률과 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec을 확률 관점에서 바라보다\n",
    "\n",
    "먼저 word2vec의 CBOW 모델을 간단히 복습해보자. \n",
    "\n",
    "말뭉치 $w_1, w_2, ...,w_{t-1},w_{t},w_{t+1},,..., w_T$ 에서 $w_{t-1}$과 $w_{t+1}$이 주어졌을 때 타깃 $w_t$가 될 확률은 다음과 같다. \n",
    "\n",
    "$$P(w_t|w_{t-1},w_{t+1})$$\n",
    "\n",
    "이번에는 맥락을 왼쪽 윈도우만으로 한정해보자.\n",
    "\n",
    "<img src=\"../imgs/fig 5-2.png\" width=\"400\" align='center'>\n",
    "\n",
    "이제 확률 식은 다음으로 같다.\n",
    "\n",
    "$$P(w_t|w_{t-2},w_{t-1})$$\n",
    "\n",
    "이전에 나온 단어들의 확률 값으로 이후 단어를 예측하는 것. 이 식으로부터 언어 모델이 등장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언어 모델\n",
    "\n",
    "언어 모델 <sup>Language Model</sup>은 **특정한 단어의 시퀀스에 대해서, 그 시퀀스가 일어날 가능성이 어느 정도인지 (얼마나 자연스러운 단어 순서인지)를 확률로 평가한다.**\n",
    "\n",
    "    - \"you say goodbye\" : 높은 확률\n",
    "    - \"you say good die\" : 낮은 확률\n",
    "\n",
    "응용 분야 \n",
    "\n",
    "- 기계 번역과 음성 인식에서 문장이 얼마나 자연스러운지 판단하여 더 높은 자연스러움을 가진 문장을 반환\n",
    "- 단어 순서의 자연스러움을 토대로 새로운 문장을 생성\n",
    "\n",
    "---\n",
    "\n",
    "#### 이제 언어 모델을 수식으로 이해해보자\n",
    "\n",
    "$w_1,...,w_m$ 이라는 m개의 단어로 된 문장을 생각해보자.\n",
    "\n",
    "이때 단어가 $w_1,...,w_m$이라는 순서로 출현할 확률을 $P(w_1,...,w_m)$의 동시 확률로 나타낼 수 있다.\n",
    "\n",
    "이 동시 확률은 다음과 같이 분해하여 쓸 수 있다. \n",
    "\n",
    "<img src=\"../imgs/e 5-4.png\" width=\"400\" align='center'>\n",
    "\n",
    "동시 확률 $P(w_1,...,w_m)$는 사후 확률의 총 곱인 $\\prod{P(w_t|w_1,...,w_{t-1})}$ 으로 대표될 수 있다.    \n",
    "여기서의 사후 확률은 **타깃 단어보다 왼쪽에 있는 모든 단어**를 맥락으로 했을 때의 확률과 같다. \n",
    "\n",
    "즉, 단어가 순서대로 출현할 확률은 동시 확률로 나타내질 수 있고, 이 동시 확률은 사후 확률의 총 곱으로 나타내질 수 있으니까. 우리의 목표는 사후 확률 $P(w_t|w_1,...,w_{t-1})$를 구하는 것!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW 모델을 언어 모델로?\n",
    "\n",
    "그렇다면 word2vec의 CBOW 모델을 억지로 언어 모델에 적용하려면??\n",
    "\n",
    "-> 맥락의 크기를 특정 값으로 한정하여 근사적으로 나타낼 수 있다! 맥락의 크기를 왼쪽 2개 단어로 한정한다면, 다음과 같이 표현 가능\n",
    "\n",
    "$P(w_1,...,w_m) = \\prod_{t=1}^{m}{P(w_t|w_1,...,w_{t-1})}\\approx \\prod_{t=1}^{m}{P(w_t|w_{t-2},w_{t-1})}$\n",
    "\n",
    "맥락의 길이는 5나 10으로 임의로 설정 가능. 어쨌거나 **맥락의 크기는 특정 크기로 고정**된다.\n",
    "\n",
    "---\n",
    "\n",
    "### 한계\n",
    "\n",
    "    이처럼 맥락의 크기가 고정될 경우 아래와 같이 맥락 크기보다 앞에 단서 단어가 나오는 케이스는 해결하기 힘들다.\n",
    "\n",
    " `Tom` was watching TV in his room. Mary came into the room. Mary said hi to `?`\n",
    "    \n",
    "   **1) 그렇다면 맥락의 크기를 20이나 30으로 키우면 되지 않을까?**\n",
    "\n",
    "    but CBOW 모델에서는 레이어 내부에서 단어 벡터들의 합계를 내는 과정에서 맥락 안의 순서가 무시되기 때문에 적합하지 않다.\n",
    "\n",
    "   **2) 엥 그렇다면 단어 벡터들 합하지 말고 concatenate하면 되지 않을까??**\n",
    "    \n",
    "    맥락의 크기에 비례해 매개변수가 증가한다. \n",
    "\n",
    "그러나 RNN의 단점도 많은 것으로 아는데..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `세상에 두달만에 다시 시작;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN이란\n",
    "\n",
    "RNN <sup>Recurrent Neural Network</sup>의 `Recurrent` : `몇 번이나 반복해서 일어나는 일, 순환한다`\n",
    "\n",
    "즉, RNN은 우리 말로 **순환 신경망**이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순환 신경망\n",
    "\n",
    "`순환`하기 위해서는 닫힌 경로 혹은 순환하는 경로가 존재해야 한다. 그래야 데이터가 순환하면서 정보가 끊임없이 갱신된다. like loop!\n",
    "\n",
    "<img src=\"../imgs/fig 5-7.png\" width=\"400\" align='center'>\n",
    "\n",
    "- 그림의 RNN계층은 $X_t$를 입력받는데, 이때 t는 시각을 뜻한다.\n",
    "- 시계열 데이터 $(x_0, x_1, x_2, x_3, ...) $ 를 의미함\n",
    "- 입력에 대응하여 $(h_0, h_1, h_2, h_3, ...) $ 가 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순환 구조 펼치기\n",
    "\n",
    "<img src=\"../imgs/fig 5-8.png\" width=\"700\" align='center'>\n",
    "\n",
    "#### vs 피드포워드 신경망   \n",
    "**같은 점**\n",
    " - RNN 계층의 순환 구조를 펼침으로써 오른쪽으로 성장하는 긴 신경망으로 변신시킬 수 있다! Like 피드포워드 신경망!   \n",
    " \n",
    "**다른 점**\n",
    "- BUT 다수의 RNN 계층 모두가 실제로는 같은 계층인 것이 다르다!\n",
    "\n",
    "---\n",
    "**각 시각의 RNN 계층은 그 계층으로의 입력과 바로 직전의 RNN 계층으로부터의 출력을 받는다. 그리고 이 두 정보를 바탕으로 현 시각의 출력을 계산한다.**\n",
    "\n",
    " $$h_t = tanh(h_{t-1}W_h + x_tW_x + b) ....[식 5.9]$$\n",
    "\n",
    "- RNN에는 가중치가 2개 있다\n",
    "    - 입력 x를 출력 h로 변환하기 위한 가중치 $W_x$ - 화살표 위\n",
    "    - 1개의 RNN 출력을 다음 시각의 출력으로 변환하기 위한 가중치 $W_h$ - 분기 화살표\n",
    "    \n",
    "\n",
    "- 식 5.9에서는 행렬 곱을 계산하고 그 합을 tanh 함수를 이용해 변환한다. 그 결과가 시각 t의 출력 $h_t$\n",
    "- **$h_t$는 다른 계층을 향해 위쪽으로 출력되는 동시에, 다음 시각의 RNN 계층(자기 자신)을 향해 오른쪽으로도 출력됨!**\n",
    "\n",
    "#### 현재의 출력 $h_t$은 한 시각 이전 출력 $h_{t-1}$에 기초해 계산된다!\n",
    "\n",
    "그래서 RNN 계층을 `메모리가 있는 계층` 이라고도 말한다.\n",
    "\n",
    "<sup>** $h_t$ : hidden state</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPTT \n",
    "\n",
    "BPTT<sup>Backpropagation Through Time</sup> ==> 시간 방향으로 펼친 신경망의 오차역전파법\n",
    "\n",
    "**BUT 긴-- 시계열 데이터 학습하기 어렵다!**\n",
    "- 시계열 데이터의 시간 크기가 커지는 것에 비례하여 BPTT가 소비하는 컴퓨팅 자원이 증가함. 메모리 DEAD ㅠㅠ\n",
    "- 기울기도 불안정해짐. Gradient Descent Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated BPTT\n",
    "\n",
    "**큰 시계열 데이터를 취급할 때, 신경망 연결을 적당한 길이로 끊어 작은 신경망 여러 개로 만든다는 아이디어**\n",
    "\n",
    "Truncated BPTT ==> 적당한 길이로 잘라낸 오차역전파법!\n",
    "\n",
    "#### **** 주의 ****\n",
    "\n",
    "- 순전파의 연결은 유지한다\n",
    "- 역전파의 연결만을 끊어낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "역전파의 연결만을 끊어낸다는 것이 무슨의미일까 \n",
    "\n",
    "<img src=\"../imgs/fig 5-11.png\" width=\"800\" align = \"center\">\n",
    "\n",
    "- RNN 계층을 길이 10개 단위로 학습할 수 있도록 역전파 연결을 끊음\n",
    "- 그보다 미래의 데이터에 대해서는 생각할 필요가 없다! **각각의 블록 단위로, 미래의 블록과는 독립적으로 오차역전파법을 완결시킴**\n",
    "\n",
    "\n",
    "<img src=\"../imgs/fig 5-14.png\" width=\"800\" align = \"center\">\n",
    "\n",
    "\n",
    "- Step 1\n",
    "\n",
    "    1) 순전파) 입력데이터 x0 - x9 (10블록) ==> h0 - h9 출력   \n",
    "    2) 역전파) dh9--->dx9 - dh0--->dx0\n",
    "    \n",
    "- Step 2\n",
    "\n",
    "    1) 순전파) Step 1의 마지막 은닉 상태인 h9를 통해 계층 연결! 입력데이터 x10 - x19 (10블록) ==> h0 - h9 출력   \n",
    "    2) 역전파) dh19--->dx19 - dh10--->dx10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated BPTT의 미니배치 학습\n",
    "\n",
    "길이가 1,000인 시계열 데이터에 대해서 시각의 길이를 10개 단위로 잘라 Truncated BPTT로 학습하는 경우!\n",
    "\n",
    "- 첫 번째 미니배치 때는 처음부터 순서대로 데이터를 제공 \n",
    "- 두 번째 미니배치 때는 500번째의 데이터를 시작위치로 정하고, 그 위치부터 다시 순서대로 데이터를 제공\n",
    "\n",
    "<img src=\"../imgs/fig 5-15.png\" width=\"600\" align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/fig 5-17.png\" width=\"600\" align = \"center\">\n",
    "\n",
    "- `RNN 계층` : Time RNN 계층 내에서 한 단계의 작업을 수행하는 계층\n",
    "- `Time RNN 계층` : T개 단계 분의 작업을 한꺼번에 처리하는 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 계층 구현\n",
    "\n",
    " $$h_t = tanh(h_{t-1}W_h + x_tW_x + b) ....[식 5.9]$$\n",
    " \n",
    "행렬 계산 시에는 형상이 중요하다!\n",
    "- 미니배치 크기가 N, 입력 벡터의 차원 수가 D, 은닉 상태 벡터의 차원 수가 H\n",
    "\n",
    "<img src=\"../imgs/fig 5-18.png\" width=\"400\" align = \"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b): # 가중치 2개와 편향 1개 인수로\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx),np.zeros_like(Wh),np.zeros_like(b)] #numpy.zeros_like : shape 유지하고 0으로 초기화\n",
    "        self.cache = None # *** 역전파 계산 시 사용하는 중간 데이터 담는 곳\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b # Main 식\n",
    "        h_next = np.tanh(t) # 다음 시각 계층으로의 입력\n",
    "        \n",
    "        self.cache = (x,h_prev,h_next)\n",
    "        return h_next\n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - h_next**2) # tanh 미분 \n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, Wh.T)\n",
    "        dWx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx,dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/fig 5-19.png\" width=\"450\" align = \"left\">\n",
    "<img src=\"../imgs/fig 5-20.png\" width=\"400\" align = \"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time RNN 계층 구현\n",
    "\n",
    "**Time RNN 계층은 T개의 RNN 계층으로 구성된다**\n",
    "\n",
    "- RNN 계층의 은닉 상태 h를 인스턴스 변수로 유지한다. 이 변수를 다음 RNN 레이어에 인계해주는 용도로 이용한다.\n",
    "\n",
    "<img src= \"../imgs/fig 5-22.png\" width=\"700\" align = \"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False): #stateful : 은닉상태 인계 받을지 여부\n",
    "        self.params = [Wx, Wh, b ]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None # T 개의 RNN 계층 리스트로 저장하는 용도\n",
    "        \n",
    "        # h : forward() 메서드 이후 마지막 RNN 계층의 은닉상태 저장\n",
    "        # dh : backward() 메서드 이후 하나의 앞 블록의 은닉 상태의 기울기 저장\n",
    "        self.h, self.dh = None, None \n",
    "        # True : 아무리 긴 시계열 데이터여도 순전파를 끊지 않고 전파\n",
    "        # False : 은닉 상태를 영행렬 (모든 요소가 0 행렬)로 초기화 \n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self,h):# 은닉상태 설정 \n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self): # 은닉상태 초기화\n",
    "        self.h = None\n",
    "        \n",
    "    # 순전파에서 입력 xs를 받는다\n",
    "    # xs : T 개 분량의 시계열 데이터를 하나로 모은 것\n",
    "    def forward(self, xs): \n",
    "        Wx, Wh, b = self.params\n",
    "        # 미니배치크기 N, 시계열 데이터 T개, 입력 벡터 차원수 D\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        # 출력값 담을 그릇\n",
    "        hs = np.empty((N, T, H), dtype = 'f') \n",
    "        \n",
    "        # \"stateful이 false\" 이거나 \"처음 호출 \" 일때 영행렬로 초기화\n",
    "        if not self.stateful or self.h is None: \n",
    "            self.h = np.zeros((N,H),dtype='f')\n",
    "            \n",
    "        # RNN 계층이 각 시간 t의 은닉 상태 h를 계산하고 이를 hs에 저장   \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params) \n",
    "            self.h = layer.forward(xs[:,t,:], self.h) \n",
    "            hs[:,t,:] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        # forward가 처음 호출되면 h에는 마지막 RNN 계층의 은닉 상태가 저장됨\n",
    "        # 다음번 forward 호출 시 stateful이 True면 먼저 저장된 h 값이 그대로 이용되고 False면 영행렬로 초기화\n",
    "        return hs\n",
    "    \n",
    "    # 역전파\n",
    "    def backward(self,dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N,T,D),dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0,0,0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            # RNN 계층의 순전파에서는 출력이 2개로 분기되어 역전파에서 각 기울기가 합산되어 전해짐\n",
    "            dx, dh = layer.backward(dhs[:,t,:] + dh) # --> 합산된 기울기\n",
    "            # dxs : 하류로 흘려보낼 기울기를 담을 그릇.. dx 여러개가 담김.\n",
    "            dxs[:,t,:] = dx \n",
    "            \n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            #각 RNN 계층의 가중치 기울기를 합산하여 최종 결과를 멤버 변수 self.grads에 덮어씀\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"../imgs/fig 5-24.png\" width=\"600\" align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시게열 데이터 처리 계층 구현\n",
    "\n",
    "RNN을 사용하여 `언어 모델`을 구현하자   \n",
    "-> RNN Language Model = RNNLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM의 전체 그림\n",
    "\n",
    "<img src = \"../imgs/fig 5-25.png\" width = \"700\" align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `Embedding 계층` : 단어 ID를 단어의 분산 표현(단어 벡터)로 변환. 이 분산 표현이 `RNN 계층`의 입력으로 들어간다.\n",
    "2. `RNN 계층` : 은닉 상태를 다음 층으로 출력함(위쪽으로) 과 동시에, 다음 시각의 `RNN 계층`으로 (오른쪽으로) 출력한다.\n",
    "3. `RNN 계층`이 위로 출력한 은닉 상태는 `Affine 계층`을 거쳐 `Softmax 계층`으로 전해진다\n",
    "\n",
    "예를 들어 you say goodbye and I say hello가 입력값으로 들어간다면\n",
    "\n",
    "- 첫 단어로 you가 입력될 때 Softmax 계층이 출력하는 확률분포를 보면 say가 가장 높다.\n",
    "- say 입력값에 대한 softmax 계층의 확률분포는 goodbye와 hello가 가장 높다.\n",
    "    - you say goodbye or you say hello 둘다 make sense\n",
    "    - **RNN 계층은 you say 라는 맥락을 기억하고 있다!**\n",
    "\n",
    "**이처럼 RNN은 지금까지 입력된 단어를 기억하고 그것을 바탕으로 다음에 출현할 단어를 예측한다!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time 계층 구현\n",
    "\n",
    "T개 분의 시계열 데이터를 한꺼번에 처리하는 계층을 Time XX계층이라 부르자.\n",
    "\n",
    "<img src = \"../imgs/fig 5-27.png\" width = \"600\" align = \"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.layers = None\n",
    "        self.W = W\n",
    "\n",
    "    def forward(self, xs):\n",
    "        N, T = xs.shape\n",
    "        V, D = self.W.shape\n",
    "        \n",
    "        out = np.empty((N,T,D),dtype='f')\n",
    "        self.layers = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = Embedding(self.W)\n",
    "            out[:,t,:] = layer.forward(xs[:,t])\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "        grad = 0\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:,t,:])\n",
    "            grad += layer.grads[0]\n",
    "            \n",
    "        self.grads[0][...] = grad\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAffine:\n",
    "    def __init__(self, W,b):\n",
    "        self.params = [W,b]\n",
    "        self.grads = [np.zeros_like(W),np.zeros_like(b)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "        \n",
    "        rx = x.reshape(N*T, -1)\n",
    "        out = np.dot(rx, W) + b\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        return out.reshape(N, T, -1)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        dout = dout.reshape(N*T, -1)\n",
    "        rx = x.reshape(N*T, -1)\n",
    "\n",
    "        db = np.sum(dout, axis=0)\n",
    "        dW = np.dot(rx.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dx = dx.reshape(*x.shape)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 Time Affine 계층은 그림처럼 T개의 Affine 계층을 준비해서 각 시각의 데이터를 개별적으로 처리하면 됨.\n",
    "\n",
    "<img src = \"../imgs/fig 5-28.png\" width = \"600\" align = \"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 버전의 Softmax\n",
    "\n",
    "class TimeSoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "        self.ignore_label = -1\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "\n",
    "        if ts.ndim == 3:  # 정답 레이블이 원핫 벡터인 경우\n",
    "            ts = ts.argmax(axis=2)\n",
    "\n",
    "        mask = (ts != self.ignore_label)\n",
    "\n",
    "        # 배치용과 시계열용을 정리(reshape)\n",
    "        xs = xs.reshape(N * T, V)\n",
    "        ts = ts.reshape(N * T)\n",
    "        mask = mask.reshape(N * T)\n",
    "\n",
    "        ys = softmax(xs)\n",
    "        ls = np.log(ys[np.arange(N * T), ts])\n",
    "        ls *= mask  # ignore_label에 해당하는 데이터는 손실을 0으로 설정\n",
    "        loss = -np.sum(ls)\n",
    "        loss /= mask.sum()\n",
    "\n",
    "        self.cache = (ts, ys, mask, (N, T, V))\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ts, ys, mask, (N, T, V) = self.cache\n",
    "\n",
    "        dx = ys\n",
    "        dx[np.arange(N * T), ts] -= 1\n",
    "        dx *= dout\n",
    "        dx /= mask.sum()\n",
    "        dx *= mask[:, np.newaxis]  # ignore_label에 해당하는 데이터는 기울기를 0으로 설정\n",
    "\n",
    "        dx = dx.reshape((N, T, V))\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"../imgs/fig 5-29.png\" width = \"600\" align = \"center\">\n",
    "\n",
    "- $x_n$은 점수를 나타냄 (확률로 정규화되기 전 값)\n",
    "- $t_n$는 정답 레이블을 나타냄\n",
    "\n",
    "- T개의 Softmax with Loss 계층 각각이 손실을 산출한다. 그리고 그 손실을 합산, 평균한 값이 최종 손실이 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNLM 학습과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM 구현\n",
    "\n",
    "<img src = \"../imgs/fig 5-30.png\" width = \"350\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V,D) / 100).astype('f')\n",
    "        ## Xavier 초깃값 이용\n",
    "        ## 이전 계층의 노드가 n개라면 표준편차가 1/sqrt(n)인 분포로 값을 초기화함\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f') \n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [],[]\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    # 신경망의 상태 초기화 메서드\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언어 모델의 평가\n",
    "\n",
    "언어 모델은 주어진 과거 단어로부터 다음에 출현할 단어의 확률분포를 출력한다.    \n",
    "이때 언어 모델의 예측 성능을 평가하는 척도로 **퍼플렉시티 (perplexity)** 를 자주 이용한다.\n",
    "\n",
    "- 퍼플렉시티 = \"확률의 역수\"  \n",
    "\n",
    "--- \n",
    "### 입력 데이터 하나일 때 예시\n",
    "\n",
    "- you say goodbye and I say hello .\n",
    "    - 모델 1 : 입력이 you일 때 정답이 say일 확률 0.8. 이때 퍼플렉시티는 1/0.8 = 1.25\n",
    "    - 모델 2 : 입력이 you일 때 정답이 say일 확률 0.2. 이때 퍼플렉시티는 1/0.2 = 5\n",
    "        - **-> 퍼플렉시티는 작을 수록 좋다!**   \n",
    "        \n",
    "        \n",
    "- 퍼플렉시티는 직관적으로  `분기 수`로 해석할 수 있다.\n",
    "    - 1.25 - 다음에 출현할 수 있는 단어의 후보가 1개 정도\n",
    "    - 5.0 - 다음에 출현할 수 있는 단어의 후보가 5개 정도 (후보가 많으니까 예측이 떨어짐)\n",
    "    \n",
    "    \n",
    "### 입력 데이터 여러 개일 때 예시\n",
    "\n",
    "$$ L = \\frac{-1}{N} \\sum_{n}\\sum_{k}t_{nk}logy_{nk} $$\n",
    "\n",
    "$$ perplexity = e^L $$\n",
    "\n",
    "- N : 데이터의 총 개수\n",
    "- $t_{n}$ : 원핫 벡터로 나타낸 정답 레이블\n",
    "- $t_{nk}$ : n개째 데이터의 k번째 값을 의미\n",
    "- $y_{nk}$ : 확률분포 ( Softmax의 출력 )\n",
    "\n",
    "**교차 엔트로피 오차와 같은 식임. 퍼플렉시티가 작을 수록 좋은 모델!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM의 학습 코드\n",
    "\n",
    "- PTB 데이터셋 1000개 단어 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 1000, 어휘 수: 418\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "# 하이퍼파라미터\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수 \n",
    "time_size = 5 # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1] # 입력\n",
    "ts = corpus[1:] # 출력(정답 레이블) - xs보다 한 단어 앞\n",
    "data_size = len(xs)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TimeSoftmaxWithLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-40030fc2a95f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleRnnlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordvec_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## 1 - 각 미니배치에서 샘플을 읽기 시작 위치를 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google 드라이브/2020/Study/[2019.12-] Keracorn/Keracorn-NLP-Study/ch05/simple_rnnlm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_size, wordvec_size, hidden_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mTimeAffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffine_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         ]\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeSoftmaxWithLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TimeSoftmaxWithLoss' is not defined"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "## 1 - 각 미니배치에서 샘플을 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in rnage(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "999 / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
