{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어텐션의 구조\n",
    "\n",
    "- seq2seq를 한층 더 강력하게 하는 **어텐션 매커니즘**\n",
    "- 인간처럼 필요한 정보에만 \"주목\"할 수 있게 만든다\n",
    "- seq2seq의 근본적인 문제를 해결한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq의 문제점\n",
    "\n",
    "- Encoder의 출력은 \"고정 길이의 벡터\"\n",
    "    - 고정 길이 벡터는 입력 문장의 길이에 관계없이 항상 같은 길이의 벡터로 변환하게 해준다\n",
    "    - **아무리 긴 벡터여도 고정 길이에 우겨넣어짐**\n",
    "\n",
    "<img src = \"../imgs/fig 8-1.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder 개선\n",
    "\n",
    "- Encoder 출력의 길이는 입력 문장에 길이에 따라 바꿔주는 것이 좋다! (당연)\n",
    "- 구체적으로는, **시각별 LSTM 계층의 은닉 상태 벡터를 모두 이용하는 것**\n",
    "\n",
    "<img src = \"../imgs/fig 8-2.png\" width=\"500\">\n",
    "\n",
    "\n",
    "#### <center>===> 이것으로 Encoder는 \"하나의 고정 길이 벡터\"라는 제약에서 벗어남</center>\n",
    "\n",
    "- (참고) RNN 계층을 초기화할 때 두 가지 반환 중 선택 가능\n",
    "    - 모든 시각의 은닉 상태 벡터 반환 \n",
    "        - [keras] `return_sequences=True`\n",
    "    - 마지막 은닉 상태 벡터만 반환\n",
    "    \n",
    "    \n",
    "- 각 시각의 은닉 상태에는 직전에 입력된 단어에 대한 정보가 많이 포함되어 있다.\n",
    "    - 예를 들어 `나` `는` `고양이` `로소` `이다` 에서 `고양이` 벡터에는 `나` `는` `고양이` 의 정보가 담겨 있다\n",
    "    - 주변 정보를 균형있게 담기 위해서는 **양방향 RNN** 이 효과적임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder 개선 ①\n",
    "\n",
    "<img src = \"../imgs/fig 8-5.png\" width=\"700\">\n",
    "\n",
    "- 앞 장의 Decoder는 Encoder의 LSTM 계층의 마지막 은닉 상태만을 이용한다 \n",
    "- hs에서 마지막 줄만 빼내어 Decoder에 전달한 것\n",
    "\n",
    "#### ===> hs 전부를 활용할 수 있도록 개선\n",
    "\n",
    "---\n",
    "\n",
    "- 사람이 문장 `나는 고양이로소이다`를 영어로 번역한다면? \n",
    "    - 나 = I, 고양이 = cat\n",
    "    - 나와 고양이가 문장의 주를 이루므로 나와 고양이라는 단어에 \"주목\" 하면서 번역을 하게 됨. 나 = I, 고양이 = cat 와 같은 단어 간 대응 관계(`alignment`)를 미리 알고 있다면 번역 효과가 더 좋을 것임.\n",
    "    - **대응 관계 (`alignment`) 아이디어 를 활용하는 것이 바로 어텐션 매커니즘**\n",
    "    \n",
    "---\n",
    "\n",
    "#### 입력과 출력의 단어 간 대응 관계를 seq2seq에게 학습시키자!!!\n",
    "\n",
    "- `도착어 단어`와 `대응 관계`에 있는 `출발어 단어`의 정보를 골라내면 더 학습(번역)이 잘 될 것 이다!\n",
    "- **필요한 정보에만 주목하여 그 정보로부터 시계열 변환을 수행하는 것이 목표**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<img src = \"../imgs/fig 8-6.png\" width=\"700\">\n",
    "\n",
    "- `어떤 계산`이 받는 입력 두 가지\n",
    "    1. Encoder로부터 받는 hs\n",
    "    2. 시각 별 LSTM 계층의 은닉 상태\n",
    "       - 여기서 필요한 정보만 골라 위쪽의 Affine계층으로 출력한다\n",
    "- Decoder의 첫번째 계층에 마지막 은닝 상태 벡터 hs를 전달하는 것은 유지\n",
    "\n",
    "- 목적은 **단어들의 대응관계 추출**\n",
    "    - 각 시각에서 Decoder에 입력된 단어와 대응관계인 단어의 벡터를 hs에서 골라내자.\n",
    "    - 예를 들어 Decoder가 `I`를 출력할 때 hs에서 `나`에 대응하는 벡터를 선택함.\n",
    "        - 그러나 일부 벡터만 선택하는 것은 미분이 가능하지 않다. ( = 오차역전파 안됨 )\n",
    "        - #### 일부 선택이 아니라 **모두 선택**하자. 대신 **가중치**를 별도로 계산\n",
    "\n",
    "\n",
    "<img src = \"../imgs/fig 8-8.png\" width=\"600\">\n",
    "\n",
    "- 각 단어의 중요도를 나타내는 가중치 $a$\n",
    "- a는 0.0 ~ 1.0 사이의 스칼라 값이며 모든 원소의 총합은 1이다\n",
    "- 각 단어의 중요성을 보여주는 가중치 a와 각 단어 벡터 hs로부터 가중 합 Weighted Sum을 구하여 원하는 벡터 얻기!\n",
    "    - 그 결과를 `맥락 벡터`라고 부르고 기호로는 c로 표기한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "(5, 4)\n",
      "[0.6241871  1.03772847 0.41861277 0.15210266]\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "T,H = 5,4\n",
    "hs = np.random.randn(T,H)\n",
    "a = np.array([0.8, 0.1, 0.03, 0.05, 0.02])\n",
    "\n",
    "ar = a.reshape(5,1).repeat(4, axis=1)\n",
    "print(ar.shape)\n",
    "\n",
    "t = hs * ar \n",
    "print(t.shape)\n",
    "\n",
    "# 단어 벡터 가중치 곱해서 합친 결과\n",
    "c = np.sum(t, axis=0) \n",
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 4)\n",
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "# 미니배치 처리용 가중합\n",
    "N, T, H  = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "a = np.random.randn(N, T)\n",
    "ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
    "\n",
    "t = hs * ar\n",
    "print(t.shape)\n",
    "\n",
    "c = np.sum(t, axis=1) # 1번 인덱스 축을 지워라\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightSum:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [],[]\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, hs, a):\n",
    "        N, T, H  = hs.shape\n",
    "        \n",
    "        ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        t = hs * ar\n",
    "        c = np.sum(t, axis=1)\n",
    "        \n",
    "        self.cache = (hs, ar)\n",
    "        return c\n",
    "\n",
    "    def backward(self, dc):\n",
    "        hs, ar = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        dt = dc.reshape(N, 1, H).repeat(T, axis = 1) #sum의 역전파\n",
    "        dar = dt * hs\n",
    "        dhs = dt * ar\n",
    "        da = np.sum(dar, axis=2) # repeat의 역전파\n",
    "        \n",
    "        return dhs, da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder 개선 ②\n",
    "\n",
    "#### <center><u> 가중치 a는 어떻게 구하나? </u></center>\n",
    "<img src = \"../imgs/fig 8-12.png\" width=\"400\">\n",
    "\n",
    "- h : Decoder 계층의 은닉 상태\n",
    "- **h가 hs의 각 단어 벡터와 얼마나 비슷한가**를 계산\n",
    "    - using 내적\n",
    "    - 두 벡터 간 내적 $ a{\\cdot}b $ : \"두 벡터가 얼마나 같은 방향을 향하고 있는가\"\n",
    "    - <img src = \"../imgs/fig 8-13.png\" width=\"400\">\n",
    "    - hs 와 h 을 내적하여 각 단어 벡터와의 유사도 구함\n",
    "    - s는 이후 소프트맥스로 0.0~1.0 사이 확률값으로 치환됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 4)\n",
      "(10, 5)\n",
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.layers import Softmax\n",
    "import numpy as np\n",
    "\n",
    "N, T, H = 10,5,4\n",
    "hs = np.random.randn(N, T, H)\n",
    "h = np.random.randn(N, H)\n",
    "hr = h.reshape(N, 1, H).repeat(T, axis=1)\n",
    "\n",
    "t = hs * hr\n",
    "print(t.shape)\n",
    "\n",
    "s = np.sum(t, axis=2)\n",
    "print(s.shape)\n",
    "\n",
    "softmax = Softmax()\n",
    "a = softmax.forward(s)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder 개선 ③\n",
    "\n",
    "<img src= \"../imgs/fig 8-16 fixed.png\" width=\"600\">\n",
    "\n",
    "1. `Attention Weight` 계층 : Encoder의 출력인 각 단어 벡터 hs에 주목하여 가중치 a 구함\n",
    "2.` Weight Sum` 계층 : a와 hs의 가중합을 구하고 맥락 벡터 c 출력\n",
    "\n",
    "**===> `Attention` 계층**\n",
    "\n",
    "<img src= \"../imgs/fig 8-17.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        # 1. 가중치 구하기\n",
    "        self.attention_weight_layer = AttentionWeight() \n",
    "        # 2. 가중합 구하기\n",
    "        self.weight_sum_layer = WeightSum()\n",
    "        self.attention_weight = None\n",
    "\n",
    "    def forward(self, hs, h):\n",
    "        a = self.attention_weight_layer.forward(hs, h)\n",
    "        out = self.weight_sum_layer.forward(hs, a)\n",
    "        self.attention_weight = a\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dhs0, da = self.weight_sum_layer.backward(dout)\n",
    "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
    "        dhs = dhs0 + dhs1\n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"../imgs/fig 8-18.png\" width=\"700\">\n",
    "\n",
    "- **LSTM 계층과 Affine 계층 사이에 Attention 계층 삽입**\n",
    "\n",
    "<img src= \"../imgs/fig 8-19.png\" width=\"500\">\n",
    "\n",
    "- [LSTM + Attention] 연결 벡터를 Affine 계층에 입력\n",
    "\n",
    "---\n",
    "\n",
    "**`Time Attention`**\n",
    "\n",
    "<img src= \"../imgs/fig 8-20.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 방향으로 펼쳐진 다수의 Attention 계층 구현\n",
    "class TimeAttention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.layers = None\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def forward(self, hs_enc, hs_dec):\n",
    "        N, T, H = hs_dec.shape\n",
    "        out = np.empty_like(hs_dec)\n",
    "        self.layers = []\n",
    "        # 각 Attention 계층의 각 단어 가중치 보관\n",
    "        self.attention_weights = []\n",
    "\n",
    "        # Attention 계층을 필요한 수만큼 만들기\n",
    "        for t in range(T): \n",
    "            layer = Attention()\n",
    "            out[:, t, :] = layer.forward(hs_enc, hs_dec[:,t,:])\n",
    "            self.layers.append(layer)\n",
    "            self.attention_weights.append(layer.attention_weight)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, H = dout.shape\n",
    "        dhs_enc = 0\n",
    "        dhs_dec = np.empty_like(dout)\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            dhs, dh = layer.backward(dout[:, t, :])\n",
    "            dhs_enc += dhs\n",
    "            dhs_dec[:,t,:] = dh\n",
    "\n",
    "        return dhs_enc, dhs_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어텐션을 갖춘 seq2seq 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어텐션 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
