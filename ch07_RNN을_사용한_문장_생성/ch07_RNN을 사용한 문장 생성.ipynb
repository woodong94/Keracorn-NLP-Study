{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 언어 모델을 사용한 문장 생성\n",
    "\n",
    "기계 번역, 음성 인식, 문장 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN을 사용한 문장 생성의 순서\n",
    "\n",
    "<center> you say goodbye and \"I\" say hello.    </center> \n",
    "<center>    *** I에 대한 확률분포 *** </center>\n",
    "    \n",
    "<img src = \"../imgs/fig 7-2.png\" width = \"200\">\n",
    "    \n",
    "#### HOW TO 생성, I 다음의 단어?\n",
    "\n",
    "1. 확률이 가장 높은 단어를 선택한다 \n",
    "    - Deterministic 한 결과\n",
    "    - 결과가 바뀌지 않음\n",
    "    - `say` 라는 단어 선택됨. 고정 불변.\n",
    "\n",
    "2. 결과를 확률에 따라 다르게\n",
    "    - 높은 단어가 선택되기 쉽고 낮은 단어는 선택되기 어려워짐\n",
    "    - `say` 라는 단어가 선택되기 쉬워짐.\n",
    "\n",
    "<img src = \"../imgs/fig 7-4.png\" width = \"400\">\n",
    "\n",
    "- 반복..반복.. until 원하는 만큼 혹은 `<eos>` 와 같은 종결 기호가 나올 때까지\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 생성 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "from ch06_게이트가_추가된_RNN.rnnlm import Rnnlm\n",
    "from ch06_게이트가_추가된_RNN.better_rnnlm import BetterRnnlm\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    # 문장 생성 수행. 100 단어까지\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        ''' start_id : 최초로 주는 단어의 ID\n",
    "            skip_ids : 해당 리스트에 속하는 단어 ID는 샘플링 되지 않도록 방지. (전처리된 단어 등)\n",
    "        '''\n",
    "        word_ids = [start_id]\n",
    "        \n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(-1,1) # 미니배치 처리때문에 x는 2차원. 1X1로 변형.\n",
    "            score = self.predict(x) # 각 단어의 점수 출력\n",
    "            p = softmax(score.flatten()) # softmax 함수 통해 정규화하여 확률분포 p 얻기\n",
    "\n",
    "            sampled = np.random.choice(len(p),size=1, p=p) # p로부터 다음 단어 샘플링\n",
    "\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "                \n",
    "        return word_ids\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you impression shared georgia nonsense bleeding devastation department-store styles ratios receiving long-distance fell phoenix raiders mateo performers enough matter feel pitches stem sentence routinely commons abortion-rights legislators iverson inaccurate forth assurance stearns va supposedly tharp mlx spree spots boren grow separately virus peck carol pitch reject something sound proving one-day u priced cargo mandate laurel we equivalent requested shipment focused franco r.h. enjoys forced proceedings method having sohmer budgetary achievement processors genuine taped startling predicted fool aging england denounced liquidated taipei mason graham photograph fe bougainville faced revise nbc refinancing until beach pride strange vickers engine sample ambitious entrenched d'arcy\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "from rnnlm_gen import RnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "model.load_params('../ch06_게이트가_추가된_RNN/Rnnlm.pkl') # 미리 학습된 가중치 불러와 성능 높임\n",
    "\n",
    "# 시작 (start) 문자와 건너뛸 (skip) 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace('<eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 별로 성능이 좋진 않음.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 좋은 문장으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterRnnlmGen(BetterRnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x).flatten()\n",
    "            p = softmax(score).flatten()\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        states = []\n",
    "        for layer in self.lstm_layers:\n",
    "            states.append((layer.h, layer.c))\n",
    "        return states\n",
    "\n",
    "    def set_state(self, states):\n",
    "        for layer, state in zip(self.lstm_layers, states):\n",
    "            layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are going to think mr. noble says .\n",
      " nothing will be on the group .\n",
      " that 's not that the business investment service does n't hold a great consideration .\n",
      " it 's only tough recently for all one devoted to the petroleum and economic services and assure good stuff .\n",
      " mr. gould says he will pay the reliance stake in a unit that is sold in associates research for the mgm grand foundation .\n",
      " and on london 's stock market reports mr. johnson notes that the diversified real estate industry is n't the only consideration that it 's not\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from rnnlm_gen import BetterRnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = BetterRnnlmGen()\n",
    "model.load_params('../ch06_게이트가_추가된_RNN/BetterRnnlm.pkl') # 미리 학습된 가중치 불러와 성능 높임\n",
    "\n",
    "# 시작 (start) 문자와 건너뛸 (skip) 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace('<eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오 결과 좋아 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"the meaning of life is\" 다음 이어지는 문장 생성하기\n",
    "\n",
    "- `the` `meaning` `of` `life` 단어를 차례로 주어 순전파 수행\n",
    "- 출력 결과는 무시하고 단어열 정보를 유지\n",
    "- 그 다음 `is`를 첫 단어로 입력해 문장 생성 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "the meaning of life is selling in texas and there are a few well-known reflected yet at least three days.\n",
      " american donations of the south korea and wisconsin.\n",
      " in an apparent letter to dpc acquisition corp. said it is trying to repurchase two competing partners as the bank of london launched a friendly pact with american medical corp. a unit of a food concern.\n",
      " the move reflected a temporary charge in japan 's real estate business.\n",
      " and analysts caution the short-term financing moves traditionally weaker some great debt will delay market share of program trading.\n",
      " it seems to make\n"
     ]
    }
   ],
   "source": [
    "model.reset_state() # not continue the previous sequences anymore, now you will start feeding new sequences.\n",
    "\n",
    "start_words = 'the meaning of life is'\n",
    "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
    "\n",
    "for x in start_ids[:-1]:\n",
    "    x = np.array(x).reshape(1, 1)\n",
    "    model.predict(x) # shape = (1, 1, 10000)\n",
    "    \n",
    "word_ids = model.generate(start_ids[-1], skip_ids)\n",
    "word_ids = start_ids[:-1] + word_ids\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print('-' * 50)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq\n",
    "\n",
    "- 시계열 데이터를 또 다른 시계열 데이터로 변환하는 문제\n",
    "    - 기계 번역 (언어 -> 언어)\n",
    "    - 음성 인식 (음성 -> 언어)\n",
    "    - 챗봇 어플리케이션 (대화 -> 대화)\n",
    "    - 컴파일러 (소스코드 -> 기계어)\n",
    " \n",
    "\n",
    "==> **시계열 데이터를 다른 시계열 데이터로 변환하는 모델**\n",
    "  \n",
    "  - 2 개의 RNN을 이용하는 **seq2seq <sup>sequence to sequence</sup>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq의 원리\n",
    "\n",
    "- seq2seq는 **Encoder-Decoder 모델**이라고도 한다\n",
    "    - `Encoder` : 입력 데이터를 인코딩 (부호화)\n",
    "    - `Decoder` : 인코딩된 데이터를 디코딩 (복호화)\n",
    "    \n",
    "    - <img src = \"../imgs/fig 7-5.png\" width = \"200\">\n",
    "\n",
    "---\n",
    "#### Encoder\n",
    "\n",
    "<img src = \"../imgs/fig 7-6.png\" width = \"700\">\n",
    "\n",
    "- RNN(LSTM)을 이용해 시계열 데이터를 **h**라는 은닉 상태 벡터로 변환\n",
    "- 문장을 단어 단위로 쪼개서 입력한다\n",
    "\n",
    "- ### `중요한 점` **LSTM의 은닉 상태 h는 고정 길이 벡터라는 사실**\n",
    "- 즉, 인코딩은 임의 길이의 문장을 고정 길이 벡터로 변환하는 작업임\n",
    "\n",
    "---\n",
    "#### Decoder\n",
    "\n",
    "<img src = \"../imgs/fig 7-8.png\" width = \"700\">\n",
    "\n",
    "- 앞 절에서 다룬 문장 생성 모델!\n",
    "- **LSTM 계층이 벡터 h를 입력받는다는 점이 차이**. \n",
    "- 앞 절의 언어 모델에서는 LSTM 계층이 아무것도 받지 않음 ㅎㅎ\n",
    "\n",
    "\n",
    "##### c.f.\n",
    "\n",
    "- `<eos>` : 문장 생성의 시작을 알리는 신호이자 종료 신호. 구분자. \n",
    "- `<go>` `<start>` `_`\n",
    "\n",
    "#### seq2seq : Encoder + Decoder\n",
    "<img src = \"../imgs/fig 7-9.png\" width = \"700\">\n",
    "\n",
    "- LSTM 두 개\n",
    "\n",
    "    - Encoder의 LSTM + Decoder의 LSTM \n",
    "    - 둘은 은닉 상태 h로 이어진다\n",
    "    \n",
    "    \n",
    "- 순전파 : Encoder -> h -> Decoder\n",
    "- 역전파 : Decoder -> h -> Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 데이터 변환용 Toy Problem\n",
    "\n",
    "<img src = \"../imgs/fig 7-10.png\" width = \"300\">\n",
    "\n",
    "#### <center>57 + 5 ==> [5, 7, + 5]</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가변 길이 시계열 데이터\n",
    "\n",
    "- **덧셈 문제에서는 샘플마다 데이터의 시간 방향 크기가 다르다!**\n",
    "- `57+5`는 4 문자, `628+123`은 7 문자\n",
    "- 가변 길이의 시계열 데이터\n",
    "\n",
    "신경망에 미니배치 처리를 하기 위한 가장 심플한 방법\n",
    "\n",
    "- **패딩 (padding)**\n",
    "    - 원래의 데이터에 의미 없는 데이터를 채워 모든 데이터 길이 동일하게 맞추기\n",
    "\n",
    "<img src = \"../imgs/fig 7-11.png\" width = \"500\">\n",
    "\n",
    "- 문제\n",
    "    - 덧셈 문제 : 0-999 사이. 최대 7 글자\n",
    "    - 정답 : 최대 999+999=1998. 최대 4글자\n",
    "    - 구분자 : `_`\n",
    "- 인풋 아웃풋\n",
    "    - 입력 : 7글자\n",
    "    - 출력 : 정답 + 구분자 = 5글자\n",
    "    \n",
    "---\n",
    "\n",
    "- 원래는 존재하지 않던 패딩용 문자까지 모델이 처리하므로 정확성 떨어짐\n",
    "- 정확성을 올리려면 추가로 패딩 전용 처리를 해줘야 함\n",
    "    - Decoder에 입력된 데이터가 패딩이라면 손실의 결과에 반영하지 않도록.\n",
    "        - ( Softmax with Loss + mask )\n",
    "    - Encdoer에 입력된 데이터가 패딩이라면 LSTM 계층이 이전 시각의 입력을 그대로 출력\n",
    "        - 원래부터 패딩은 없었어..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
