{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 살펴본 신경망은 피드포워드 유형의 신경망이다. 피드포워드란 흐름이 단방향을 신경망을 말한다.\n",
    "\n",
    "그러나 피드포워드 신경망은 **시계열 데이터의 성질(패턴)을 충분히 학습할 수 없다**는 커다란 단점이 있다.\n",
    "\n",
    "그래서 **순환 신경망 <sup>Recurrent Neural Network</sup> (RNN)** 이 등장하게 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 확률과 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec을 확률 관점에서 바라보다\n",
    "\n",
    "먼저 word2vec의 CBOW 모델을 간단히 복습해보자. \n",
    "\n",
    "말뭉치 $w_1, w_2, ...,w_{t-1},w_{t},w_{t+1},,..., w_T$ 에서 $w_{t-1}$과 $w_{t+1}$이 주어졌을 때 타깃 $w_t$가 될 확률은 다음과 같다. \n",
    "\n",
    "$$P(w_t|w_{t-1},w_{t+1})$$\n",
    "\n",
    "이번에는 맥락을 왼쪽 윈도우만으로 한정해보자.\n",
    "\n",
    "<img src=\"../imgs/fig 5-2.png\" width=\"400\" align='center'>\n",
    "\n",
    "이제 확률 식은 다음으로 같다.\n",
    "\n",
    "$$P(w_t|w_{t-2},w_{t-1})$$\n",
    "\n",
    "이전에 나온 단어들의 확률 값으로 이후 단어를 예측하는 것. 이 식으로부터 언어 모델이 등장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언어 모델\n",
    "\n",
    "언어 모델 <sup>Language Model</sup>은 **특정한 단어의 시퀀스에 대해서, 그 시퀀스가 일어날 가능성이 어느 정도인지 (얼마나 자연스러운 단어 순서인지)를 확률로 평가한다.**\n",
    "\n",
    "    - \"you say goodbye\" : 높은 확률\n",
    "    - \"you say good die\" : 낮은 확률\n",
    "\n",
    "응용 분야 \n",
    "\n",
    "- 기계 번역과 음성 인식에서 문장이 얼마나 자연스러운지 판단하여 더 높은 자연스러움을 가진 문장을 반환\n",
    "- 단어 순서의 자연스러움을 토대로 새로운 문장을 생성\n",
    "\n",
    "---\n",
    "\n",
    "#### 이제 언어 모델을 수식으로 이해해보자\n",
    "\n",
    "$w_1,...,w_m$ 이라는 m개의 단어로 된 문장을 생각해보자.\n",
    "\n",
    "이때 단어가 $w_1,...,w_m$이라는 순서로 출현할 확률을 $P(w_1,...,w_m)$의 동시 확률로 나타낼 수 있다.\n",
    "\n",
    "이 동시 확률은 다음과 같이 분해하여 쓸 수 있다. \n",
    "\n",
    "<img src=\"../imgs/e 5-4.png\" width=\"400\" align='center'>\n",
    "\n",
    "동시 확률 $P(w_1,...,w_m)$는 사후 확률의 총 곱인 $\\prod{P(w_t|w_1,...,w_{t-1})}$ 으로 대표될 수 있다.    \n",
    "여기서의 사후 확률은 **타깃 단어보다 왼쪽에 있는 모든 단어**를 맥락으로 했을 때의 확률과 같다. \n",
    "\n",
    "즉, 단어가 순서대로 출현할 확률은 동시 확률로 나타내질 수 있고, 이 동시 확률은 사후 확률의 총 곱으로 나타내질 수 있으니까. 우리의 목표는 사후 확률 $P(w_t|w_1,...,w_{t-1})$를 구하는 것!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW 모델을 언어 모델로?\n",
    "\n",
    "그렇다면 word2vec의 CBOW 모델을 억지로 언어 모델에 적용하려면??\n",
    "\n",
    "-> 맥락의 크기를 특정 값으로 한정하여 근사적으로 나타낼 수 있다! 맥락의 크기를 왼쪽 2개 단어로 한정한다면, 다음과 같이 표현 가능\n",
    "\n",
    "$P(w_1,...,w_m) = \\prod_{t=1}^{m}{P(w_t|w_1,...,w_{t-1})}\\approx \\prod_{t=1}^{m}{P(w_t|w_{t-2},w_{t-1})}$\n",
    "\n",
    "맥락의 길이는 5나 10으로 임의로 설정 가능. 어쨌거나 **맥락의 크기는 특정 크기로 고정**된다.\n",
    "\n",
    "---\n",
    "\n",
    "### 한계\n",
    "\n",
    "    이처럼 맥락의 크기가 고정될 경우 아래와 같이 맥락 크기보다 앞에 단서 단어가 나오는 케이스는 해결하기 힘들다.\n",
    "\n",
    " `Tom` was watching TV in his room. Mary came into the room. Mary said hi to `?`\n",
    "    \n",
    "   **1) 그렇다면 맥락의 크기를 20이나 30으로 키우면 되지 않을까?**\n",
    "\n",
    "    but CBOW 모델에서는 레이어 내부에서 단어 벡터들의 합계를 내는 과정에서 맥락 안의 순서가 무시되기 때문에 적합하지 않다.\n",
    "\n",
    "   **2) 엥 그렇다면 단어 벡터들 합하지 말고 concatenate하면 되지 않을까??**\n",
    "    \n",
    "    맥락의 크기에 비례해 매개변수가 증가한다. \n",
    "\n",
    "그러나 RNN의 단점도 많은 것으로 아는데..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `세상에 두달만에 다시 시작;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN이란\n",
    "\n",
    "RNN <sup>Recurrent Neural Network</sup>의 `Recurrent` : `몇 번이나 반복해서 일어나는 일, 순환한다`\n",
    "\n",
    "즉, RNN은 우리 말로 **순환 신경망**이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순환 신경망\n",
    "\n",
    "`순환`하기 위해서는 닫힌 경로 혹은 순환하는 경로가 존재해야 한다. 그래야 데이터가 순환하면서 정보가 끊임없이 갱신된다. like loop!\n",
    "\n",
    "<img src=\"../imgs/fig 5-7.png\" width=\"400\" align='center'>\n",
    "\n",
    "- 그림의 RNN계층은 $X_t$를 입력받는데, 이때 t는 시각을 뜻한다.\n",
    "- 시계열 데이터 $(x_0, x_1, x_2, x_3, ...) $ 를 의미함\n",
    "- 입력에 대응하여 $(h_0, h_1, h_2, h_3, ...) $ 가 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순환 구조 펼치기\n",
    "\n",
    "<img src=\"../imgs/fig 5-8.png\" width=\"700\" align='center'>\n",
    "\n",
    "#### vs 피드포워드 신경망   \n",
    "**같은 점**\n",
    " - RNN 계층의 순환 구조를 펼침으로써 오른쪽으로 성장하는 긴 신경망으로 변신시킬 수 있다! Like 피드포워드 신경망!   \n",
    " \n",
    "**다른 점**\n",
    "- BUT 다수의 RNN 계층 모두가 실제로는 같은 계층인 것이 다르다!\n",
    "\n",
    "---\n",
    "**각 시각의 RNN 계층은 그 계층으로의 입력과 바로 직전의 RNN 계층으로부터의 출력을 받는다. 그리고 이 두 정보를 바탕으로 현 시각의 출력을 계산한다.**\n",
    "\n",
    " $$h_t = tanh(h_{t-1}W_h + x_tW_x + b) ....[식 5.9]$$\n",
    "\n",
    "- RNN에는 가중치가 2개 있다\n",
    "    - 입력 x를 출력 h로 변환하기 위한 가중치 $W_x$ - 화살표 위\n",
    "    - 1개의 RNN 출력을 다음 시각의 출력으로 변환하기 위한 가중치 $W_h$ - 분기 화살표\n",
    "    \n",
    "\n",
    "- 식 5.9에서는 행렬 곱을 계산하고 그 합을 tanh 함수를 이용해 변환한다. 그 결과가 시각 t의 출력 $h_t$\n",
    "- **$h_t$는 다른 계층을 향해 위쪽으로 출력되는 동시에, 다음 시각의 RNN 계층(자기 자신)을 향해 오른쪽으로도 출력됨!**\n",
    "\n",
    "#### 현재의 출력 $h_t$은 한 시각 이전 출력 $h_{t-1}$에 기초해 계산된다!\n",
    "\n",
    "그래서 RNN 계층을 `메모리가 있는 계층` 이라고도 말한다.\n",
    "\n",
    "<sup>** $h_t$ : hidden state</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPTT \n",
    "\n",
    "BPTT<sup>Backpropagation Through Time</sup> ==> 시간 방향으로 펼친 신경망의 오차역전파법\n",
    "\n",
    "**BUT 긴-- 시계열 데이터 학습하기 어렵다!**\n",
    "- 시계열 데이터의 시간 크기가 커지는 것에 비례하여 BPTT가 소비하는 컴퓨팅 자원이 증가함. 메모리 DEAD ㅠㅠ\n",
    "- 기울기도 불안정해짐. Gradient Descent Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated BPTT\n",
    "\n",
    "**큰 시계열 데이터를 취급할 때, 신경망 연결을 적당한 길이로 끊어 작은 신경망 여러 개로 만든다는 아이디어**\n",
    "\n",
    "Truncated BPTT ==> 적당한 길이로 잘라낸 오차역전파법!\n",
    "\n",
    "#### **** 주의 ****\n",
    "\n",
    "- 순전파의 연결은 유지한다\n",
    "- 역전파의 연결만을 끊어낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "역전파의 연결만을 끊어낸다는 것이 무슨의미일까 \n",
    "\n",
    "<img src=\"../imgs/fig 5-11.png\" width=\"800\" align = \"center\">\n",
    "\n",
    "- RNN 계층을 길이 10개 단위로 학습할 수 있도록 역전파 연결을 끊음\n",
    "- 그보다 미래의 데이터에 대해서는 생각할 필요가 없다! **각각의 블록 단위로, 미래의 블록과는 독립적으로 오차역전파법을 완결시킴**\n",
    "\n",
    "\n",
    "<img src=\"../imgs/fig 5-14.png\" width=\"800\" align = \"center\">\n",
    "\n",
    "\n",
    "- Step 1\n",
    "\n",
    "    1) 순전파) 입력데이터 x0 - x9 (10블록) ==> h0 - h9 출력   \n",
    "    2) 역전파) dh9--->dx9 - dh0--->dx0\n",
    "    \n",
    "- Step 2\n",
    "\n",
    "    1) 순전파) Step 1의 마지막 은닉 상태인 h9를 통해 계층 연결! 입력데이터 x10 - x19 (10블록) ==> h0 - h9 출력   \n",
    "    2) 역전파) dh19--->dx19 - dh10--->dx10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated BPTT의 미니배치 학습\n",
    "\n",
    "길이가 1,000인 시계열 데이터에 대해서 시각의 길이를 10개 단위로 잘라 Truncated BPTT로 학습하는 경우!\n",
    "\n",
    "- 첫 번째 미니배치 때는 처음부터 순서대로 데이터를 제공 \n",
    "- 두 번째 미니배치 때는 500번째의 데이터를 시작위치로 정하고, 그 위치부터 다시 순서대로 데이터를 제공\n",
    "\n",
    "<img src=\"../imgs/fig 5-15.png\" width=\"600\" align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/fig 5-17.png\" width=\"600\" align = \"center\">\n",
    "\n",
    "- `RNN 계층` : Time RNN 계층 내에서 한 단계의 작업을 수행하는 계층\n",
    "- `Time RNN 계층` : T개 단계 분의 작업을 한꺼번에 처리하는 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 계층 구현\n",
    "\n",
    " $$h_t = tanh(h_{t-1}W_h + x_tW_x + b) ....[식 5.9]$$\n",
    " \n",
    "행렬 계산 시에는 형상이 중요하다!\n",
    "- 미니배치 크기가 N, 입력 벡터의 차원 수가 D, 은닉 상태 벡터의 차원 수가 H\n",
    "\n",
    "<img src=\"../imgs/fig 5-18.png\" width=\"400\" align = \"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b): # 가중치 2개와 편향 1개 인수로\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx),np.zeros_like(Wh),np.zeros_like(b)] #numpy.zeros_like : shape 유지하고 0으로 초기화\n",
    "        self.cache = None # *** 역전파 계산 시 사용하는 중간 데이터 담는 곳\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b # Main 식\n",
    "        h_next = np.tanh(t) # 다음 시각 계층으로의 입력\n",
    "        \n",
    "        self.cache = (x,h_prev,h_next)\n",
    "        return h_next\n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - h_next**2) # tanh 미분 \n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, Wh.T)\n",
    "        dWx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx,dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/fig 5-19.png\" width=\"450\" align = \"left\">\n",
    "<img src=\"../imgs/fig 5-20.png\" width=\"400\" align = \"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time RNN 계층 구현\n",
    "\n",
    "**Time RNN 계층은 T개의 RNN 계층으로 구성된다**\n",
    "\n",
    "- RNN 계층의 은닉 상태 h를 인스턴스 변수로 유지한다. 이 변수를 다음 RNN 레이어에 인계해주는 용도로 이용한다.\n",
    "\n",
    "<img src= \"../imgs/fig 5-22.png\" width=\"700\" align = \"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False): #stateful : 은닉상태 인계 받을지 여부\n",
    "        self.params = [Wx, Wh, b ]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None # T 개의 RNN 계층 리스트로 저장하는 용도\n",
    "         \n",
    "        self.h = None # forward() 메서드 이후 마지막 RNN 계층의 은닉상태 저장\n",
    "        self.dh = None # backward() 메서드 이후 하나의 앞 블록의 은닉 상태의 기울기 저장\n",
    "        \n",
    "        # True : 아무리 긴 시계열 데이터여도 순전파를 끊지 않고 전파\n",
    "        # False : 은닉 상태를 영행렬 (모든 요소가 0 행렬)로 초기화 \n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self,h):# 은닉상태 설정 \n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self): # 은닉상태 초기화\n",
    "        self.h = None\n",
    "        \n",
    "    # 순전파에서 입력 xs를 받는다\n",
    "    # xs : T 개 분량의 시계열 데이터를 하나로 모은 것\n",
    "    def forward(self, xs): \n",
    "        Wx, Wh, b = self.params\n",
    "        # 미니배치크기 N, 시계열 데이터 T개, 입력 벡터 차원수 D\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        # 출력값 담을 그릇\n",
    "        hs = np.empty((N, T, H), dtype = 'f') \n",
    "        \n",
    "        # \"stateful이 false\" 이거나 \"처음 호출 \" 일때 영행렬로 초기화\n",
    "        if not self.stateful or self.h is None: \n",
    "            self.h = np.zeros((N,H),dtype='f')\n",
    "            \n",
    "        # RNN 계층이 각 시간 t의 은닉 상태 h를 계산하고 이를 hs에 저장   \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params) \n",
    "            self.h = layer.forward(xs[:,t,:], self.h) \n",
    "            hs[:,t,:] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        # forward가 처음 호출되면 h에는 마지막 RNN 계층의 은닉 상태가 저장됨\n",
    "        # 다음번 forward 호출 시 stateful이 True면 먼저 저장된 h 값이 그대로 이용되고 False면 영행렬로 초기화\n",
    "        return hs\n",
    "    \n",
    "    # 역전파\n",
    "    def backward(self,dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N,T,D),dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0,0,0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            # RNN 계층의 순전파에서는 출력이 2개로 분기되어 역전파에서 각 기울기가 합산되어 전해짐\n",
    "            dx, dh = layer.backward(dhs[:,t,:] + dh) # --> 합산된 기울기\n",
    "            # dxs : 하류로 흘려보낼 기울기를 담을 그릇.. dx 여러개가 담김.\n",
    "            dxs[:,t,:] = dx \n",
    "            \n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            #각 RNN 계층의 가중치 기울기를 합산하여 최종 결과를 멤버 변수 self.grads에 덮어씀\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"../imgs/fig 5-24.png\" width=\"600\" align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시게열 데이터 처리 계층 구현\n",
    "\n",
    "RNN을 사용하여 `언어 모델`을 구현하자   \n",
    "-> RNN Language Model = RNNLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM의 전체 그림\n",
    "\n",
    "<img src = \"../imgs/fig 5-25.png\" width = \"700\" align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `Embedding 계층` : 단어 ID를 단어의 분산 표현(단어 벡터)로 변환. 이 분산 표현이 `RNN 계층`의 입력으로 들어간다.\n",
    "2. `RNN 계층` : 은닉 상태를 다음 층으로 출력함(위쪽으로) 과 동시에, 다음 시각의 `RNN 계층`으로 (오른쪽으로) 출력한다.\n",
    "3. `RNN 계층`이 위로 출력한 은닉 상태는 `Affine 계층`을 거쳐 `Softmax 계층`으로 전해진다\n",
    "\n",
    "예를 들어 you say goodbye and I say hello가 입력값으로 들어간다면\n",
    "\n",
    "- 첫 단어로 you가 입력될 때 Softmax 계층이 출력하는 확률분포를 보면 say가 가장 높다.\n",
    "- say 입력값에 대한 softmax 계층의 확률분포는 goodbye와 hello가 가장 높다.\n",
    "    - you say goodbye or you say hello 둘다 make sense\n",
    "    - **RNN 계층은 you say 라는 맥락을 기억하고 있다!**\n",
    "\n",
    "**이처럼 RNN은 지금까지 입력된 단어를 기억하고 그것을 바탕으로 다음에 출현할 단어를 예측한다!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time 계층 구현\n",
    "\n",
    "T개 분의 시계열 데이터를 한꺼번에 처리하는 계층을 Time XX계층이라 부르자.\n",
    "\n",
    "<img src = \"../imgs/fig 5-27.png\" width = \"600\" align = \"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.layers = None\n",
    "        self.W = W\n",
    "\n",
    "    def forward(self, xs):\n",
    "        N, T = xs.shape\n",
    "        V, D = self.W.shape\n",
    "        \n",
    "        out = np.empty((N,T,D),dtype='f')\n",
    "        self.layers = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = Embedding(self.W)\n",
    "            out[:,t,:] = layer.forward(xs[:,t])\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "        grad = 0\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:,t,:])\n",
    "            grad += layer.grads[0]\n",
    "            \n",
    "        self.grads[0][...] = grad\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAffine:\n",
    "    def __init__(self, W,b):\n",
    "        self.params = [W,b]\n",
    "        self.grads = [np.zeros_like(W),np.zeros_like(b)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "        \n",
    "        rx = x.reshape(N*T, -1)\n",
    "        out = np.dot(rx, W) + b\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        return out.reshape(N, T, -1)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        dout = dout.reshape(N*T, -1)\n",
    "        rx = x.reshape(N*T, -1)\n",
    "\n",
    "        db = np.sum(dout, axis=0)\n",
    "        dW = np.dot(rx.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dx = dx.reshape(*x.shape)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 Time Affine 계층은 그림처럼 T개의 Affine 계층을 준비해서 각 시각의 데이터를 개별적으로 처리하면 됨.\n",
    "\n",
    "<img src = \"../imgs/fig 5-28.png\" width = \"600\" align = \"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 버전의 Softmax\n",
    "class TimeSoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "        self.ignore_label = -1\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "\n",
    "        if ts.ndim == 3:  # 정답 레이블이 원핫 벡터인 경우\n",
    "            ts = ts.argmax(axis=2)\n",
    "\n",
    "        mask = (ts != self.ignore_label)\n",
    "\n",
    "        # 배치용과 시계열용을 정리(reshape)\n",
    "        xs = xs.reshape(N * T, V)\n",
    "        ts = ts.reshape(N * T)\n",
    "        mask = mask.reshape(N * T)\n",
    "\n",
    "        ys = softmax(xs)\n",
    "        ls = np.log(ys[np.arange(N * T), ts])\n",
    "        ls *= mask  # ignore_label에 해당하는 데이터는 손실을 0으로 설정\n",
    "        loss = -np.sum(ls)\n",
    "        loss /= mask.sum()\n",
    "\n",
    "        self.cache = (ts, ys, mask, (N, T, V))\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ts, ys, mask, (N, T, V) = self.cache\n",
    "\n",
    "        dx = ys\n",
    "        dx[np.arange(N * T), ts] -= 1\n",
    "        dx *= dout\n",
    "        dx /= mask.sum()\n",
    "        dx *= mask[:, np.newaxis]  # ignore_label에 해당하는 데이터는 기울기를 0으로 설정\n",
    "\n",
    "        dx = dx.reshape((N, T, V))\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"../imgs/fig 5-29.png\" width = \"600\" align = \"center\">\n",
    "\n",
    "- $x_n$은 점수를 나타냄 (확률로 정규화되기 전 값)\n",
    "- $t_n$는 정답 레이블을 나타냄\n",
    "\n",
    "- T개의 Softmax with Loss 계층 각각이 손실을 산출한다. 그리고 그 손실을 합산, 평균한 값이 최종 손실이 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNLM 학습과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM 구현\n",
    "\n",
    "<img src = \"../imgs/fig 5-30.png\" width = \"350\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V,D) / 100).astype('f')\n",
    "        ## Xavier 초깃값 이용\n",
    "        ## 이전 계층의 노드가 n개라면 표준편차가 1/sqrt(n)인 분포로 값을 초기화함\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f') \n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [],[]\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    # 신경망의 상태 초기화 메서드\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언어 모델의 평가\n",
    "\n",
    "언어 모델은 주어진 과거 단어로부터 다음에 출현할 단어의 확률분포를 출력한다.    \n",
    "이때 언어 모델의 예측 성능을 평가하는 척도로 **퍼플렉시티 (perplexity)** 를 자주 이용한다.\n",
    "\n",
    "- 퍼플렉시티 = \"확률의 역수\"  \n",
    "\n",
    "--- \n",
    "### 입력 데이터 하나일 때 예시\n",
    "\n",
    "- you say goodbye and I say hello .\n",
    "    - 모델 1 : 입력이 you일 때 정답이 say일 확률 0.8. 이때 퍼플렉시티는 1/0.8 = 1.25\n",
    "    - 모델 2 : 입력이 you일 때 정답이 say일 확률 0.2. 이때 퍼플렉시티는 1/0.2 = 5\n",
    "        - **-> 퍼플렉시티는 작을 수록 좋다!**   \n",
    "        \n",
    "        \n",
    "- 퍼플렉시티는 직관적으로  `분기 수`로 해석할 수 있다.\n",
    "    - 1.25 - 다음에 출현할 수 있는 단어의 후보가 1개 정도\n",
    "    - 5.0 - 다음에 출현할 수 있는 단어의 후보가 5개 정도 (후보가 많으니까 예측이 떨어짐)\n",
    "    \n",
    "    \n",
    "### 입력 데이터 여러 개일 때 예시\n",
    "\n",
    "$$ L = \\frac{-1}{N} \\sum_{n}\\sum_{k}t_{nk}logy_{nk} $$\n",
    "\n",
    "$$ perplexity = e^L $$\n",
    "\n",
    "- N : 데이터의 총 개수\n",
    "- $t_{n}$ : 원핫 벡터로 나타낸 정답 레이블\n",
    "- $t_{nk}$ : n개째 데이터의 k번째 값을 의미\n",
    "- $y_{nk}$ : 확률분포 ( Softmax의 출력 )\n",
    "\n",
    "**교차 엔트로피 오차와 같은 식임. 퍼플렉시티가 작을 수록 좋은 모델!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM의 학습 코드\n",
    "\n",
    "- PTB 데이터셋 1000개 단어 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 1000, 어휘 수: 418\n",
      "| epoch 1 | perplexity 399.72\n",
      "| epoch 2 | perplexity 278.50\n",
      "| epoch 3 | perplexity 226.73\n",
      "| epoch 4 | perplexity 217.86\n",
      "| epoch 5 | perplexity 208.28\n",
      "| epoch 6 | perplexity 202.46\n",
      "| epoch 7 | perplexity 199.55\n",
      "| epoch 8 | perplexity 196.42\n",
      "| epoch 9 | perplexity 190.47\n",
      "| epoch 10 | perplexity 191.64\n",
      "| epoch 11 | perplexity 187.49\n",
      "| epoch 12 | perplexity 191.19\n",
      "| epoch 13 | perplexity 188.52\n",
      "| epoch 14 | perplexity 189.09\n",
      "| epoch 15 | perplexity 187.31\n",
      "| epoch 16 | perplexity 184.72\n",
      "| epoch 17 | perplexity 181.25\n",
      "| epoch 18 | perplexity 178.71\n",
      "| epoch 19 | perplexity 178.92\n",
      "| epoch 20 | perplexity 179.26\n",
      "| epoch 21 | perplexity 179.90\n",
      "| epoch 22 | perplexity 173.38\n",
      "| epoch 23 | perplexity 169.31\n",
      "| epoch 24 | perplexity 170.63\n",
      "| epoch 25 | perplexity 172.04\n",
      "| epoch 26 | perplexity 167.07\n",
      "| epoch 27 | perplexity 161.81\n",
      "| epoch 28 | perplexity 161.34\n",
      "| epoch 29 | perplexity 157.18\n",
      "| epoch 30 | perplexity 149.53\n",
      "| epoch 31 | perplexity 151.97\n",
      "| epoch 32 | perplexity 147.08\n",
      "| epoch 33 | perplexity 142.66\n",
      "| epoch 34 | perplexity 137.77\n",
      "| epoch 35 | perplexity 135.47\n",
      "| epoch 36 | perplexity 131.70\n",
      "| epoch 37 | perplexity 124.72\n",
      "| epoch 38 | perplexity 122.58\n",
      "| epoch 39 | perplexity 116.64\n",
      "| epoch 40 | perplexity 110.79\n",
      "| epoch 41 | perplexity 111.90\n",
      "| epoch 42 | perplexity 106.48\n",
      "| epoch 43 | perplexity 103.52\n",
      "| epoch 44 | perplexity 97.07\n",
      "| epoch 45 | perplexity 91.88\n",
      "| epoch 46 | perplexity 90.59\n",
      "| epoch 47 | perplexity 85.85\n",
      "| epoch 48 | perplexity 82.86\n",
      "| epoch 49 | perplexity 78.76\n",
      "| epoch 50 | perplexity 74.02\n",
      "| epoch 51 | perplexity 71.41\n",
      "| epoch 52 | perplexity 68.47\n",
      "| epoch 53 | perplexity 64.23\n",
      "| epoch 54 | perplexity 60.57\n",
      "| epoch 55 | perplexity 58.77\n",
      "| epoch 56 | perplexity 54.78\n",
      "| epoch 57 | perplexity 52.84\n",
      "| epoch 58 | perplexity 49.30\n",
      "| epoch 59 | perplexity 46.96\n",
      "| epoch 60 | perplexity 43.87\n",
      "| epoch 61 | perplexity 42.94\n",
      "| epoch 62 | perplexity 40.32\n",
      "| epoch 63 | perplexity 38.06\n",
      "| epoch 64 | perplexity 35.92\n",
      "| epoch 65 | perplexity 34.10\n",
      "| epoch 66 | perplexity 31.27\n",
      "| epoch 67 | perplexity 31.27\n",
      "| epoch 68 | perplexity 28.83\n",
      "| epoch 69 | perplexity 27.17\n",
      "| epoch 70 | perplexity 26.33\n",
      "| epoch 71 | perplexity 24.52\n",
      "| epoch 72 | perplexity 23.56\n",
      "| epoch 73 | perplexity 22.15\n",
      "| epoch 74 | perplexity 20.52\n",
      "| epoch 75 | perplexity 20.41\n",
      "| epoch 76 | perplexity 18.66\n",
      "| epoch 77 | perplexity 17.75\n",
      "| epoch 78 | perplexity 16.60\n",
      "| epoch 79 | perplexity 15.85\n",
      "| epoch 80 | perplexity 14.76\n",
      "| epoch 81 | perplexity 13.98\n",
      "| epoch 82 | perplexity 13.44\n",
      "| epoch 83 | perplexity 12.76\n",
      "| epoch 84 | perplexity 11.94\n",
      "| epoch 85 | perplexity 11.23\n",
      "| epoch 86 | perplexity 11.42\n",
      "| epoch 87 | perplexity 10.64\n",
      "| epoch 88 | perplexity 10.12\n",
      "| epoch 89 | perplexity 9.60\n",
      "| epoch 90 | perplexity 9.21\n",
      "| epoch 91 | perplexity 8.80\n",
      "| epoch 92 | perplexity 7.93\n",
      "| epoch 93 | perplexity 7.71\n",
      "| epoch 94 | perplexity 7.72\n",
      "| epoch 95 | perplexity 7.48\n",
      "| epoch 96 | perplexity 7.31\n",
      "| epoch 97 | perplexity 6.85\n",
      "| epoch 98 | perplexity 6.36\n",
      "| epoch 99 | perplexity 5.96\n",
      "| epoch 100 | perplexity 5.61\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "# 하이퍼파라미터\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수 \n",
    "time_size = 5 # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1] # 입력\n",
    "ts = corpus[1:] # 출력(정답 레이블) - xs보다 한 단어 앞\n",
    "data_size = len(xs) # 999\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "########################################\n",
    "# 1 - 각 미니배치에서 샘플을 읽을 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "#[0, 99, 198, 297, 396, 495, 594, 693, 792, 891] -> 오프셋의 각 원소에 데이터를 읽는 시작 위치가 담긴다!\n",
    "########################################\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        ########################################\n",
    "        # 2 - 미니배치 획득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype = 'i') #그릇 준비\n",
    "        batch_t = np.empty((batch_size, time_size), dtype = 'i') ##그릇 준비\n",
    "        for t in range(time_size): # time idx를 순차적으로 늘리면서 말뭉치에서 time idx위치의 데이터를 확보한다\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i,t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i,t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "        ########################################\n",
    "        \n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "    ########################################    \n",
    "    # 3 - 에포크마다 퍼플렉시티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print(\"| epoch %d | perplexity %.2f\" % (epoch+1,ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0,0\n",
    "    ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "sns.lineplot(list(range(100)),ppl_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM의 Trainer 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class RnnlmTrainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.time_idx = None\n",
    "        self.ppl_list = None\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "        \n",
    "    def get_batch(self, x, t, batch_size, time_size):\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "\n",
    "        data_size = len(x)\n",
    "        jump = data_size // batch_size\n",
    "        offsets = [i * jump for i in range(batch_size)]  # 배치에서 각 샘플을 읽기 시작하는 위치\n",
    "\n",
    "        for time in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
    "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
    "            self.time_idx += 1\n",
    "        return batch_x, batch_t\n",
    "\n",
    "    def fit(self, xs, ts, max_epoch=10, batch_size=20, time_size=35,\n",
    "            max_grad=None, eval_interval=20):\n",
    "        data_size = len(xs)\n",
    "        max_iters = data_size // (batch_size * time_size)\n",
    "        self.time_idx = 0\n",
    "        self.ppl_list = []\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            for iters in range(max_iters):\n",
    "                batch_x, batch_t = self.get_batch(xs, ts, batch_size, time_size) # 미니배치 순차적으로 만들기\n",
    "\n",
    "                # 기울기를 구해 매개변수 갱신\n",
    "                loss = model.forward(batch_x, batch_t) # 순전파 호출\n",
    "                model.backward() # 역전파 호출\n",
    "                params, grads = remove_duplicate(model.params, model.grads)  # 공유된 가중치를 하나로 모음\n",
    "                if max_grad is not None:\n",
    "                    clip_grads(grads, max_grad)\n",
    "                optimizer.update(params, grads) # 옵티마이저로 가중치 갱신\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                # 퍼플렉서티 평가\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    ppl = np.exp(total_loss / loss_count)\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print('| 에폭 %d |  반복 %d / %d | 시간 %d[s] | 퍼플렉서티 %.2f'\n",
    "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, ppl))\n",
    "                    self.ppl_list.append(float(ppl))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = numpy.arange(len(self.ppl_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.ppl_list, label='train')\n",
    "        plt.xlabel('반복 (x' + str(self.eval_interval) + ')')\n",
    "        plt.ylabel('퍼플렉서티')\n",
    "        plt.show()\n",
    "        \n",
    "def remove_duplicate(params, grads):\n",
    "    '''\n",
    "    매개변수 배열 중 중복되는 가중치를 하나로 모아\n",
    "    그 가중치에 대응하는 기울기를 더한다.\n",
    "    '''\n",
    "    params, grads = params[:], grads[:]  # copy list\n",
    "\n",
    "    while True:\n",
    "        find_flg = False\n",
    "        L = len(params)\n",
    "\n",
    "        for i in range(0, L - 1):\n",
    "            for j in range(i + 1, L):\n",
    "                # 가중치 공유 시\n",
    "                if params[i] is params[j]:\n",
    "                    grads[i] += grads[j]  # 경사를 더함\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "                # 가중치를 전치행렬로 공유하는 경우(weight tying)\n",
    "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
    "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
    "                    grads[i] += grads[j].T\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "\n",
    "                if find_flg: break\n",
    "            if find_flg: break\n",
    "\n",
    "        if not find_flg: break\n",
    "\n",
    "    return params, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 415.79\n",
      "| 에폭 2 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 372.66\n",
      "| 에폭 3 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 257.59\n",
      "| 에폭 4 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 222.06\n",
      "| 에폭 5 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 211.43\n",
      "| 에폭 6 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 210.20\n",
      "| 에폭 7 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 201.32\n",
      "| 에폭 8 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 201.43\n",
      "| 에폭 9 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 196.19\n",
      "| 에폭 10 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 191.46\n",
      "| 에폭 11 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 192.36\n",
      "| 에폭 12 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 189.57\n",
      "| 에폭 13 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 192.87\n",
      "| 에폭 14 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 188.23\n",
      "| 에폭 15 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 186.76\n",
      "| 에폭 16 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 190.96\n",
      "| 에폭 17 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 189.56\n",
      "| 에폭 18 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 184.49\n",
      "| 에폭 19 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 181.11\n",
      "| 에폭 20 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 181.67\n",
      "| 에폭 21 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 178.91\n",
      "| 에폭 22 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 177.66\n",
      "| 에폭 23 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 180.68\n",
      "| 에폭 24 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 177.67\n",
      "| 에폭 25 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 170.70\n",
      "| 에폭 26 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 171.31\n",
      "| 에폭 27 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 170.18\n",
      "| 에폭 28 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 171.31\n",
      "| 에폭 29 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 164.13\n",
      "| 에폭 30 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 158.95\n",
      "| 에폭 31 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 157.40\n",
      "| 에폭 32 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 152.10\n",
      "| 에폭 33 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 149.94\n",
      "| 에폭 34 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 148.05\n",
      "| 에폭 35 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 140.57\n",
      "| 에폭 36 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 137.21\n",
      "| 에폭 37 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 136.64\n",
      "| 에폭 38 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 126.57\n",
      "| 에폭 39 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 123.44\n",
      "| 에폭 40 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 120.14\n",
      "| 에폭 41 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 115.31\n",
      "| 에폭 42 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 113.55\n",
      "| 에폭 43 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 108.18\n",
      "| 에폭 44 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 103.72\n",
      "| 에폭 45 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 97.51\n",
      "| 에폭 46 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 94.73\n",
      "| 에폭 47 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 92.23\n",
      "| 에폭 48 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 87.84\n",
      "| 에폭 49 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 83.50\n",
      "| 에폭 50 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 77.82\n",
      "| 에폭 51 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 77.03\n",
      "| 에폭 52 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 71.78\n",
      "| 에폭 53 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 68.64\n",
      "| 에폭 54 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 63.96\n",
      "| 에폭 55 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 62.03\n",
      "| 에폭 56 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 58.56\n",
      "| 에폭 57 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 56.98\n",
      "| 에폭 58 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 51.86\n",
      "| 에폭 59 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 49.33\n",
      "| 에폭 60 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 47.10\n",
      "| 에폭 61 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 44.65\n",
      "| 에폭 62 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 42.94\n",
      "| 에폭 63 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 40.45\n",
      "| 에폭 64 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 37.40\n",
      "| 에폭 65 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 34.73\n",
      "| 에폭 66 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 33.68\n",
      "| 에폭 67 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 31.42\n",
      "| 에폭 68 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 30.20\n",
      "| 에폭 69 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 28.40\n",
      "| 에폭 70 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 26.02\n",
      "| 에폭 71 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 24.73\n",
      "| 에폭 72 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 24.03\n",
      "| 에폭 73 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 22.17\n",
      "| 에폭 74 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 20.80\n",
      "| 에폭 75 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 19.82\n",
      "| 에폭 76 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 18.30\n",
      "| 에폭 77 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 17.78\n",
      "| 에폭 78 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 16.17\n",
      "| 에폭 79 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 15.91\n",
      "| 에폭 80 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 14.74\n",
      "| 에폭 81 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 13.72\n",
      "| 에폭 82 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 13.96\n",
      "| 에폭 83 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 13.13\n",
      "| 에폭 84 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 12.62\n",
      "| 에폭 85 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 11.66\n",
      "| 에폭 86 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 10.59\n",
      "| 에폭 87 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 10.46\n",
      "| 에폭 88 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 9.54\n",
      "| 에폭 89 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 9.73\n",
      "| 에폭 90 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 8.94\n",
      "| 에폭 91 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 8.71\n",
      "| 에폭 92 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 8.74\n",
      "| 에폭 93 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 8.01\n",
      "| 에폭 94 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 7.45\n",
      "| 에폭 95 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.68\n",
      "| 에폭 96 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.65\n",
      "| 에폭 97 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.04\n",
      "| 에폭 98 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 5.92\n",
      "| 에폭 99 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 5.73\n",
      "| 에폭 100 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 5.72\n"
     ]
    }
   ],
   "source": [
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size) \n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
